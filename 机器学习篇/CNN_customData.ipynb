{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用PyTorch进行卷积神经网络（CNN）的训练，您需要按照以下步骤操作：\n",
    "\n",
    "1. **定义数据集类**：如果您有自定义的数据集，您需要使用`torch.utils.data.Dataset`来封装您的数据和标签。\n",
    "2. **构建CNN模型**：定义一个继承自`torch.nn.Module`的类来构建您的CNN。\n",
    "3. **定义损失函数和优化器**：选择适合您任务的损失函数和优化器。\n",
    "4. **训练模型**：编写训练循环，使用您的数据训练模型。\n",
    "5. **评估模型**：在验证集或测试集上评估模型的性能。\n",
    "\n",
    "下面是一个简化的例子，展示如何使用PyTorch进行这一过程：\n",
    "\n",
    "### 步骤 1: 定义数据集类\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "```\n",
    "\n",
    "### 步骤 2: 构建CNN模型\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "### 步骤 3: 定义损失函数和优化器\n",
    "\n",
    "```python\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "```\n",
    "\n",
    "### 步骤 4: 训练模型\n",
    "\n",
    "```python\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Assuming your data and labels are numpy arrays\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, labels = ... # your data and labels\n",
    "\n",
    "# Convert data and labels to PyTorch tensors\n",
    "data = torch.tensor(data, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = CustomDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train your model\n",
    "train_model(model, dataloader, criterion, optimizer)\n",
    "```\n",
    "\n",
    "### 步骤 5: 评估模型\n",
    "\n",
    "这一步通常涉及在一个独立的测试集上运行模型，并使用例如准确率这样的指标来评估性能。\n",
    "\n",
    "请注意，这个例子假设您的数据是图像数据，且已经适当地归一化和预处理。您可能需要根据您的具体数据和任务调整CNN结构、损失函数和其他参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练完成后，使用测试数据进行模型评估是检查模型泛化能力的重要步骤。下面是一个详细的步骤说明，展示如何在PyTorch中使用测试数据对一个训练好的模型进行评估。\n",
    "\n",
    "### 步骤 1: 准备测试数据\n",
    "确保你的测试数据集已经按照和训练数据相同的方式进行预处理。这包括数据的归一化、重塑等步骤。然后，使用`DataLoader`来加载测试数据，这样可以方便地在评估过程中批量处理数据。\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# 假设 test_data 和 test_labels 已经被正确处理并转换为Tensor\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "```\n",
    "\n",
    "### 步骤 2: 设置模型为评估模式\n",
    "在评估之前，确保将模型设置为评估模式。这样可以关闭如Dropout和Batch Normalization等只在训练时有用的层。\n",
    "\n",
    "```python\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "### 步骤 3: 评估模型\n",
    "关闭梯度计算，使用测试数据集来评估模型的性能。通常，我们会计算并记录诸如准确率、损失等指标。\n",
    "\n",
    "```python\n",
    "import torch.nn.functional as F\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        loss = F.cross_entropy(outputs, labels)  # 计算损失\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "average_loss = total_loss / len(test_loader)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy of the model on the test data: {100 * accuracy}%')\n",
    "print(f'Average loss: {average_loss}')\n",
    "```\n",
    "\n",
    "### 步骤 4: 分析结果\n",
    "根据模型在测试集上的表现来分析模型的性能。高准确率和低损失指示模型有较好的泛化能力。如果模型在训练集上表现良好，但在测试集上表现不佳，则可能存在过拟合。\n",
    "\n",
    "### 步骤 5: 进一步的测试\n",
    "根据需要进行更多的测试，例如混淆矩阵、精确度、召回率和F1分数等，这些都可以帮助你更全面地了解模型的性能。\n",
    "\n",
    "通过这些步骤，你可以有效地评估你的模型，并根据测试结果进行必要的调整和优化。这是确保模型在实际应用中能够可靠工作的关键步骤。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完整工程展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# 检查CUDA是否可用，如果可用则使用CUDA，否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "''' \n",
    "自定义数据集，需要定义好‘__getitem__’函数\n",
    "'''\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "    \n",
    "# 定义一个简单的CNN模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 4, 16)\n",
    "        self.fc2 = nn.Linear(16, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 4 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "# 读取数据集\n",
    "data_train = np.loadtxt('./ECG5000/data/ECG5000_TRAIN.txt')\n",
    "\n",
    "# 获取data和label\n",
    "X_train, y_train = data_train[:, 1:], data_train[:, 0]-1.0\n",
    "\n",
    "new_X_train = np.zeros([X_train.shape[0], 16, 16])\n",
    "new_X_train[:,0:10, 0:14] = X_train.reshape([X_train.shape[0],10,14])\n",
    "\n",
    "data, labels = new_X_train, y_train\n",
    "\n",
    "# Convert data and labels to PyTorch tensors\n",
    "data = torch.tensor(data, dtype=torch.float32).unsqueeze(1)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = CustomDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Plotting the histogram of the labels\n",
    "plt.hist(labels.numpy(), bins=np.arange(11)-0.5, edgecolor='black')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Histogram of Label Distribution')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.show()\n",
    "\n",
    "# 定义模型，损失函数以及优化器\n",
    "model = SimpleCNN()\n",
    "model.to(device)\n",
    "\n",
    "# 统计模型参数量\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    # print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "    print(f\"Layer: {name} | Size: {param.size()} \\n\") # 打印每一层距离名称、参数大小和参数数值\n",
    "    num_params = param.numel()\n",
    "    total_params += num_params\n",
    "    \n",
    "print(f\"Total number: {total_params*4} Bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练步骤\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    model.to(device)  # Move the model to the device (GPU or CPU)\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, labels in dataloader:\n",
    "            if device.type == 'cuda':\n",
    "                data, labels = data.to(device), labels.to(device)  # Move data and labels to the device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "        \n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "# Train your model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据集\n",
    "# data_train = np.loadtxt('./ECG5000/data/ECG5000_TRAIN.txt')\n",
    "data_test = np.loadtxt('./ECG5000/data/ECG5000_TEST.txt')\n",
    "\n",
    "# 获取data和label\n",
    "X_test, y_test = data_test[:, 1:], data_test[:, 0]-1.0\n",
    "\n",
    "# 评估模型\n",
    "new_X_test = np.zeros([X_test.shape[0], 16, 16])\n",
    "new_X_test[:,0:10, 0:14] = X_test.reshape([X_test.shape[0],10,14])\n",
    "\n",
    "test_data, test_labels = new_X_test, y_test\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32).unsqueeze(1)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "test_dataset = CustomDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for data, labels in test_loader:\n",
    "        if device.type == 'cuda':\n",
    "            data, labels = data.to(device), labels.to(device)  # Move data and labels to the device\n",
    "        outputs = model(data)\n",
    "        loss = F.cross_entropy(outputs, labels)  # 计算损失\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        y_pred.extend(predicted.cpu().numpy())  # 收集预测结果\n",
    "        y_true.extend(labels.cpu().numpy())     # 收集真实标签\n",
    "\n",
    "average_loss = total_loss / len(test_loader)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy of the model on the test data: {100 * accuracy}%')\n",
    "print(f'Average loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 使用matplotlib绘制混淆矩阵\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(cm, cmap=plt.cm.Oranges)  # 选择颜色映射\n",
    "\n",
    "# 为图添加颜色条\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# 设置坐标轴\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xticklabels([''] + list(np.unique(y_pred)))\n",
    "ax.set_yticklabels([''] + list(np.unique(y_pred)))\n",
    "\n",
    "# 在混淆矩阵的各个单元格中添加数值标签\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, f'{val}', ha='center', va='center', color='black')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 实现 NumPy 功能\n",
    "def conv2d(input, weight, bias, stride, padding):\n",
    "    batch_size, in_channels, in_height, in_width = input.shape\n",
    "    out_channels, _, kernel_height, kernel_width = weight.shape\n",
    "    out_height = (in_height + 2 * padding - kernel_height) // stride + 1\n",
    "    out_width = (in_width + 2 * padding - kernel_width) // stride + 1\n",
    "    \n",
    "    # Padding\n",
    "    input_padded = np.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    \n",
    "    # Output tensor\n",
    "    output = np.zeros((batch_size, out_channels, out_height, out_width))\n",
    "    \n",
    "    # Convolution\n",
    "    for y in range(out_height):\n",
    "        for x in range(out_width):\n",
    "            for o in range(out_channels):\n",
    "                output[:, o, y, x] = np.sum(\n",
    "                    input_padded[:, :, y*stride:y*stride+kernel_height, x*stride:x*stride+kernel_width] * weight[o, :, :, :], axis=(1, 2, 3)) + bias[o]\n",
    "    return output\n",
    "\n",
    "def max_pool2d(input, kernel_size, stride):\n",
    "    batch_size, channels, in_height, in_width = input.shape\n",
    "    out_height = (in_height - kernel_size) // stride + 1\n",
    "    out_width = (in_width - kernel_size) // stride + 1\n",
    "    output = np.zeros((batch_size, channels, out_height, out_width))\n",
    "    \n",
    "    for y in range(out_height):\n",
    "        for x in range(out_width):\n",
    "            output[:, :, y, x] = np.max(input[:, :, y*stride:y*stride+kernel_size, x*stride:x*stride+kernel_size], axis=(2, 3))\n",
    "    return output\n",
    "\n",
    "def relu(input):\n",
    "    return np.maximum(0, input)\n",
    "\n",
    "def linear(input, weight, bias):\n",
    "    return input.dot(weight.T) + bias\n",
    "\n",
    "def cnn_forward(input_data, params):\n",
    "    # 前向推理\n",
    "    x = conv2d(input_data, params['conv1.weight'], params['conv1.bias'], stride=1, padding=1)\n",
    "    x = relu(x)\n",
    "    x = max_pool2d(x, kernel_size=2, stride=2)\n",
    "    x = conv2d(x, params['conv2.weight'], params['conv2.bias'], stride=1, padding=1)\n",
    "    x = relu(x)\n",
    "    x = max_pool2d(x, kernel_size=2, stride=2)\n",
    "    x = x.reshape(x.shape[0], -1)  # Flatten\n",
    "    x = relu(linear(x, params['fc1.weight'], params['fc1.bias']))\n",
    "    output = linear(x, params['fc2.weight'], params['fc2.bias'])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# 假设输入数据\n",
    "input_data = np.random.rand(1, 1, 16, 16).astype(np.float32)  # (batch_size, channels, height, width)\n",
    "\n",
    "# 实例化模型并提取参数\n",
    "params = {name: param.detach().cpu().numpy() for name, param in model.named_parameters()}\n",
    "\n",
    "# 随机抽取一个测试样本\n",
    "rd_idx = np.random.randint(test_labels.shape[0])\n",
    "input_data = test_data[rd_idx,:].reshape([1,1,test_data.shape[2],test_data.shape[3]])\n",
    "print(input_data.shape)\n",
    "\n",
    "# numpy前向推理\n",
    "output = cnn_forward(input_data, params)\n",
    "\n",
    "# 模型原生推理结果\n",
    "input_data = input_data.to(device)\n",
    "output2 = model(input_data)\n",
    "output2 = output2.detach().cpu().numpy()\n",
    "\n",
    "# 打印两种推理方式的结果，可以看到是一致的\n",
    "print(output, '\\n' , output2)\n",
    "\n",
    "# 预测label\n",
    "predict_ = np.argmax(output)\n",
    "print(f\"预测类型：{predict_}, 真值： {test_labels[rd_idx]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
