{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step0：定义LSTM模型类、制作Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "class ECGClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(ECGClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM 输出大小：(batch_size, seq_length, hidden_dim)\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        # 选择最后一个时间步的输出\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2：定义模型、损失函数、优化器以及训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# 检查CUDA是否可用，如果可用则使用CUDA，否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 读取数据集\n",
    "data_train = np.loadtxt('../ECG5000/data/ECG5000_TEST.txt')\n",
    "\n",
    "# 获取data和label\n",
    "data, labels = data_train[:, 1:], data_train[:, 0]-1.0 # 这里-1.0是为了将标签从0开始\n",
    "\n",
    "# 转换成tensor张量\n",
    "data = torch.tensor(data, dtype=torch.float32).unsqueeze(1)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# 使用 np.unique 获取所有唯一标签\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# 获取唯一标签的数量\n",
    "num_unique_labels = len(unique_labels)\n",
    "# print(num_unique_labels)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = CustomDataset(data, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# model = ECGClassifier(input_dim=140, hidden_dim=64, num_layers=4, num_classes=num_unique_labels)\n",
    "model = ECGClassifier(input_dim=140, hidden_dim=4, num_layers=2, num_classes=num_unique_labels)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打印模型结构、参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: lstm\n",
      "Structure: LSTM(140, 4, num_layers=2, batch_first=True)\n",
      "\n",
      "Layer: fc\n",
      "Structure: Linear(in_features=4, out_features=5, bias=True)\n",
      "\n",
      "weight_ih_l0: torch.Size([16, 140])\n",
      "weight_hh_l0: torch.Size([16, 4])\n",
      "bias_ih_l0: torch.Size([16])\n",
      "bias_hh_l0: torch.Size([16])\n",
      "weight_ih_l1: torch.Size([16, 4])\n",
      "weight_hh_l1: torch.Size([16, 4])\n",
      "bias_ih_l1: torch.Size([16])\n",
      "bias_hh_l1: torch.Size([16])\n",
      " \n",
      "--------------------------------\n",
      "\n",
      "Layer: lstm.weight_ih_l0 | Size: torch.Size([16, 140]) | Number of Parameters: 2240\n",
      "Layer: lstm.weight_hh_l0 | Size: torch.Size([16, 4]) | Number of Parameters: 64\n",
      "Layer: lstm.bias_ih_l0 | Size: torch.Size([16]) | Number of Parameters: 16\n",
      "Layer: lstm.bias_hh_l0 | Size: torch.Size([16]) | Number of Parameters: 16\n",
      "Layer: lstm.weight_ih_l1 | Size: torch.Size([16, 4]) | Number of Parameters: 64\n",
      "Layer: lstm.weight_hh_l1 | Size: torch.Size([16, 4]) | Number of Parameters: 64\n",
      "Layer: lstm.bias_ih_l1 | Size: torch.Size([16]) | Number of Parameters: 16\n",
      "Layer: lstm.bias_hh_l1 | Size: torch.Size([16]) | Number of Parameters: 16\n",
      "Layer: fc.weight | Size: torch.Size([5, 4]) | Number of Parameters: 20\n",
      "Layer: fc.bias | Size: torch.Size([5]) | Number of Parameters: 5\n",
      " \n",
      "--------------------------------\n",
      "\n",
      "模型总参数量: 10084 Bytes \n"
     ]
    }
   ],
   "source": [
    "for name, layer in model.named_children():\n",
    "    print(f\"Layer: {name}\")\n",
    "    print(f\"Structure: {layer}\")\n",
    "    if hasattr(layer, 'activation'):\n",
    "        print(f\"Activation Function: {layer.activation}\")\n",
    "    print()\n",
    "    \n",
    "lstm_params = list(model.lstm.named_parameters())\n",
    "for name, param in lstm_params:\n",
    "    print(f\"{name}: {param.size()}\")\n",
    "    \n",
    "print(\" \\n--------------------------------\\n\")\n",
    "  \n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    num_params = param.numel()\n",
    "    total_params += num_params\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Number of Parameters: {num_params}\")\n",
    "\n",
    "print(\" \\n--------------------------------\\n\")\n",
    "\n",
    "print(f\"模型总参数量: {total_params * 4} Bytes \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3：开始模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Step [100/282], Loss: 1.3987\n",
      "Epoch [1/80], Step [200/282], Loss: 1.3803\n",
      "Epoch [2/80], Step [100/282], Loss: 1.1938\n",
      "Epoch [2/80], Step [200/282], Loss: 1.2035\n",
      "Epoch [3/80], Step [100/282], Loss: 1.0764\n",
      "Epoch [3/80], Step [200/282], Loss: 1.0950\n",
      "Epoch [4/80], Step [100/282], Loss: 0.8203\n",
      "Epoch [4/80], Step [200/282], Loss: 0.7030\n",
      "Epoch [5/80], Step [100/282], Loss: 0.6661\n",
      "Epoch [5/80], Step [200/282], Loss: 0.5727\n",
      "Epoch [6/80], Step [100/282], Loss: 0.6226\n",
      "Epoch [6/80], Step [200/282], Loss: 0.5998\n",
      "Epoch [7/80], Step [100/282], Loss: 0.5346\n",
      "Epoch [7/80], Step [200/282], Loss: 0.6361\n",
      "Epoch [8/80], Step [100/282], Loss: 0.3381\n",
      "Epoch [8/80], Step [200/282], Loss: 0.4885\n",
      "Epoch [9/80], Step [100/282], Loss: 0.4375\n",
      "Epoch [9/80], Step [200/282], Loss: 0.3352\n",
      "Epoch [10/80], Step [100/282], Loss: 0.4534\n",
      "Epoch [10/80], Step [200/282], Loss: 0.4365\n",
      "Epoch [11/80], Step [100/282], Loss: 0.1767\n",
      "Epoch [11/80], Step [200/282], Loss: 0.2519\n",
      "Epoch [12/80], Step [100/282], Loss: 0.5259\n",
      "Epoch [12/80], Step [200/282], Loss: 0.1937\n",
      "Epoch [13/80], Step [100/282], Loss: 0.1570\n",
      "Epoch [13/80], Step [200/282], Loss: 0.5016\n",
      "Epoch [14/80], Step [100/282], Loss: 0.4956\n",
      "Epoch [14/80], Step [200/282], Loss: 0.1360\n",
      "Epoch [15/80], Step [100/282], Loss: 0.2522\n",
      "Epoch [15/80], Step [200/282], Loss: 0.1126\n",
      "Epoch [16/80], Step [100/282], Loss: 0.3352\n",
      "Epoch [16/80], Step [200/282], Loss: 0.1860\n",
      "Epoch [17/80], Step [100/282], Loss: 0.5169\n",
      "Epoch [17/80], Step [200/282], Loss: 0.1097\n",
      "Epoch [18/80], Step [100/282], Loss: 0.3384\n",
      "Epoch [18/80], Step [200/282], Loss: 0.2377\n",
      "Epoch [19/80], Step [100/282], Loss: 0.3680\n",
      "Epoch [19/80], Step [200/282], Loss: 0.2904\n",
      "Epoch [20/80], Step [100/282], Loss: 0.6336\n",
      "Epoch [20/80], Step [200/282], Loss: 0.0700\n",
      "Epoch [21/80], Step [100/282], Loss: 0.0714\n",
      "Epoch [21/80], Step [200/282], Loss: 0.1601\n",
      "Epoch [22/80], Step [100/282], Loss: 0.0563\n",
      "Epoch [22/80], Step [200/282], Loss: 0.2272\n",
      "Epoch [23/80], Step [100/282], Loss: 0.2435\n",
      "Epoch [23/80], Step [200/282], Loss: 0.0664\n",
      "Epoch [24/80], Step [100/282], Loss: 0.1388\n",
      "Epoch [24/80], Step [200/282], Loss: 0.2384\n",
      "Epoch [25/80], Step [100/282], Loss: 0.1259\n",
      "Epoch [25/80], Step [200/282], Loss: 0.2485\n",
      "Epoch [26/80], Step [100/282], Loss: 0.2491\n",
      "Epoch [26/80], Step [200/282], Loss: 0.0319\n",
      "Epoch [27/80], Step [100/282], Loss: 0.2455\n",
      "Epoch [27/80], Step [200/282], Loss: 0.4609\n",
      "Epoch [28/80], Step [100/282], Loss: 0.0747\n",
      "Epoch [28/80], Step [200/282], Loss: 0.0576\n",
      "Epoch [29/80], Step [100/282], Loss: 0.1870\n",
      "Epoch [29/80], Step [200/282], Loss: 0.6677\n",
      "Epoch [30/80], Step [100/282], Loss: 0.0601\n",
      "Epoch [30/80], Step [200/282], Loss: 0.2369\n",
      "Epoch [31/80], Step [100/282], Loss: 0.1085\n",
      "Epoch [31/80], Step [200/282], Loss: 0.3165\n",
      "Epoch [32/80], Step [100/282], Loss: 0.0393\n",
      "Epoch [32/80], Step [200/282], Loss: 0.3156\n",
      "Epoch [33/80], Step [100/282], Loss: 0.0544\n",
      "Epoch [33/80], Step [200/282], Loss: 0.3501\n",
      "Epoch [34/80], Step [100/282], Loss: 0.2292\n",
      "Epoch [34/80], Step [200/282], Loss: 0.0625\n",
      "Epoch [35/80], Step [100/282], Loss: 0.1868\n",
      "Epoch [35/80], Step [200/282], Loss: 0.0184\n",
      "Epoch [36/80], Step [100/282], Loss: 0.0465\n",
      "Epoch [36/80], Step [200/282], Loss: 0.2297\n",
      "Epoch [37/80], Step [100/282], Loss: 0.2218\n",
      "Epoch [37/80], Step [200/282], Loss: 0.1352\n",
      "Epoch [38/80], Step [100/282], Loss: 0.1024\n",
      "Epoch [38/80], Step [200/282], Loss: 0.2057\n",
      "Epoch [39/80], Step [100/282], Loss: 0.1643\n",
      "Epoch [39/80], Step [200/282], Loss: 0.2098\n",
      "Epoch [40/80], Step [100/282], Loss: 0.0413\n",
      "Epoch [40/80], Step [200/282], Loss: 0.0465\n",
      "Epoch [41/80], Step [100/282], Loss: 0.0212\n",
      "Epoch [41/80], Step [200/282], Loss: 0.2379\n",
      "Epoch [42/80], Step [100/282], Loss: 0.0965\n",
      "Epoch [42/80], Step [200/282], Loss: 0.2657\n",
      "Epoch [43/80], Step [100/282], Loss: 0.2262\n",
      "Epoch [43/80], Step [200/282], Loss: 0.1794\n",
      "Epoch [44/80], Step [100/282], Loss: 0.3607\n",
      "Epoch [44/80], Step [200/282], Loss: 0.0869\n",
      "Epoch [45/80], Step [100/282], Loss: 0.1681\n",
      "Epoch [45/80], Step [200/282], Loss: 0.2438\n",
      "Epoch [46/80], Step [100/282], Loss: 0.0403\n",
      "Epoch [46/80], Step [200/282], Loss: 0.0909\n",
      "Epoch [47/80], Step [100/282], Loss: 0.0459\n",
      "Epoch [47/80], Step [200/282], Loss: 0.1654\n",
      "Epoch [48/80], Step [100/282], Loss: 0.0311\n",
      "Epoch [48/80], Step [200/282], Loss: 0.3768\n",
      "Epoch [49/80], Step [100/282], Loss: 0.2630\n",
      "Epoch [49/80], Step [200/282], Loss: 0.1564\n",
      "Epoch [50/80], Step [100/282], Loss: 0.2103\n",
      "Epoch [50/80], Step [200/282], Loss: 0.2872\n",
      "Epoch [51/80], Step [100/282], Loss: 0.0895\n",
      "Epoch [51/80], Step [200/282], Loss: 0.4389\n",
      "Epoch [52/80], Step [100/282], Loss: 0.4979\n",
      "Epoch [52/80], Step [200/282], Loss: 0.1474\n",
      "Epoch [53/80], Step [100/282], Loss: 0.2499\n",
      "Epoch [53/80], Step [200/282], Loss: 0.4929\n",
      "Epoch [54/80], Step [100/282], Loss: 0.0251\n",
      "Epoch [54/80], Step [200/282], Loss: 0.0471\n",
      "Epoch [55/80], Step [100/282], Loss: 0.1127\n",
      "Epoch [55/80], Step [200/282], Loss: 0.1330\n",
      "Epoch [56/80], Step [100/282], Loss: 0.0539\n",
      "Epoch [56/80], Step [200/282], Loss: 0.0943\n",
      "Epoch [57/80], Step [100/282], Loss: 0.5308\n",
      "Epoch [57/80], Step [200/282], Loss: 0.6154\n",
      "Epoch [58/80], Step [100/282], Loss: 0.0831\n",
      "Epoch [58/80], Step [200/282], Loss: 0.2265\n",
      "Epoch [59/80], Step [100/282], Loss: 0.0385\n",
      "Epoch [59/80], Step [200/282], Loss: 0.1299\n",
      "Epoch [60/80], Step [100/282], Loss: 0.4290\n",
      "Epoch [60/80], Step [200/282], Loss: 0.2185\n",
      "Epoch [61/80], Step [100/282], Loss: 0.0784\n",
      "Epoch [61/80], Step [200/282], Loss: 0.0246\n",
      "Epoch [62/80], Step [100/282], Loss: 0.0201\n",
      "Epoch [62/80], Step [200/282], Loss: 0.1537\n",
      "Epoch [63/80], Step [100/282], Loss: 0.2258\n",
      "Epoch [63/80], Step [200/282], Loss: 0.0255\n",
      "Epoch [64/80], Step [100/282], Loss: 0.4331\n",
      "Epoch [64/80], Step [200/282], Loss: 0.1487\n",
      "Epoch [65/80], Step [100/282], Loss: 0.3063\n",
      "Epoch [65/80], Step [200/282], Loss: 0.3945\n",
      "Epoch [66/80], Step [100/282], Loss: 0.0581\n",
      "Epoch [66/80], Step [200/282], Loss: 0.0649\n",
      "Epoch [67/80], Step [100/282], Loss: 0.2748\n",
      "Epoch [67/80], Step [200/282], Loss: 0.0745\n",
      "Epoch [68/80], Step [100/282], Loss: 0.0663\n",
      "Epoch [68/80], Step [200/282], Loss: 0.3322\n",
      "Epoch [69/80], Step [100/282], Loss: 0.1530\n",
      "Epoch [69/80], Step [200/282], Loss: 0.0504\n",
      "Epoch [70/80], Step [100/282], Loss: 0.2621\n",
      "Epoch [70/80], Step [200/282], Loss: 0.3485\n",
      "Epoch [71/80], Step [100/282], Loss: 0.5419\n",
      "Epoch [71/80], Step [200/282], Loss: 0.0180\n",
      "Epoch [72/80], Step [100/282], Loss: 0.0717\n",
      "Epoch [72/80], Step [200/282], Loss: 0.0728\n",
      "Epoch [73/80], Step [100/282], Loss: 0.2747\n",
      "Epoch [73/80], Step [200/282], Loss: 0.1456\n",
      "Epoch [74/80], Step [100/282], Loss: 0.0213\n",
      "Epoch [74/80], Step [200/282], Loss: 0.0130\n",
      "Epoch [75/80], Step [100/282], Loss: 0.0994\n",
      "Epoch [75/80], Step [200/282], Loss: 0.0756\n",
      "Epoch [76/80], Step [100/282], Loss: 0.0762\n",
      "Epoch [76/80], Step [200/282], Loss: 0.0323\n",
      "Epoch [77/80], Step [100/282], Loss: 0.0227\n",
      "Epoch [77/80], Step [200/282], Loss: 0.3308\n",
      "Epoch [78/80], Step [100/282], Loss: 0.4364\n",
      "Epoch [78/80], Step [200/282], Loss: 0.0332\n",
      "Epoch [79/80], Step [100/282], Loss: 0.0133\n",
      "Epoch [79/80], Step [200/282], Loss: 0.2483\n",
      "Epoch [80/80], Step [100/282], Loss: 0.1021\n",
      "Epoch [80/80], Step [200/282], Loss: 0.0921\n"
     ]
    }
   ],
   "source": [
    "# 定义训练过程\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device='cpu'):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (signals, labels) in enumerate(train_loader):\n",
    "            # 前向传播\n",
    "            # print(signals.shape)\n",
    "            signals, labels = signals.to(device), labels.to(device)\n",
    "            outputs = model(signals)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "                \n",
    "# 开始执行模型训练\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=80, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4：测试集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data: 95.42222222222222%\n",
      "Average loss: 0.16117828369176843\n"
     ]
    }
   ],
   "source": [
    "## Step4：测试集验证\n",
    "# 读取测试数据集\n",
    "data_test = np.loadtxt('../ECG5000/data/ECG5000_TEST.txt')\n",
    "\n",
    "# 获取data和label\n",
    "test_data, test_labels = data_train[:, 1:], data_train[:, 0]-1.0\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32).unsqueeze(1)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "test_dataset = CustomDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "total_loss = 0.0\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for data, labels in test_loader:\n",
    "        if device.type == 'cuda':\n",
    "            data, labels = data.to(device), labels.to(device)  # Move data and labels to the device\n",
    "        outputs = model(data)\n",
    "        loss = F.cross_entropy(outputs, labels)  # 计算损失\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        y_pred.extend(predicted.cpu().numpy())  # 收集预测结果\n",
    "        y_true.extend(labels.cpu().numpy())     # 收集真实标签\n",
    "\n",
    "average_loss = total_loss / len(test_loader)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy of the model on the test data: {100 * accuracy}%')\n",
    "print(f'Average loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: 绘制confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charles\\AppData\\Local\\Temp\\ipykernel_9336\\3463582496.py:16: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + list(np.unique(y_pred)))\n",
      "C:\\Users\\Charles\\AppData\\Local\\Temp\\ipykernel_9336\\3463582496.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + list(np.unique(y_pred)))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAG1CAYAAABkoPeiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMyklEQVR4nO3de1xT9f8H8Nc2HaCwKSobBCJmKnhBRUWyVJRENPNaWV7wkn4tsJQ0tW+hmUVpmpdM7VuK9ZO0TMnUNMIQTUxFyVuSF0wsAa8boHLZzu8PcrpwORxwxs7r+Xh8HrlzPufsvdPY3nt/PuccmSAIAoiIiEiy5GIHQEREROJiMkBERCRxTAaIiIgkjskAERGRxDEZICIikjgmA0RERBLHZICIiEjimAwQERFJHJMBIiIiiWMyQEREJHFMBirZsmXL0KRJEzg7OyM4OBj79+8XOyS7kpqaiv79+8PLywsymQyJiYlih2SX4uLi0KlTJ7i5ucHDwwMDBw5EZmam2GHZneXLl6Nt27ZQqVRQqVQICQnB999/L3ZYRDUOk4FKtH79esTExGDWrFk4dOgQAgMDER4ejry8PLFDsxuFhYUIDAzEsmXLxA7Fru3atQtRUVHYt28fkpKSUFJSgt69e6OwsFDs0OyKt7c33nvvPaSnp+PgwYPo2bMnBgwYgOPHj4sdGlGNIuONiipPcHAwOnXqhI8++ggAYDQa4ePjg0mTJmHGjBkiR2d/ZDIZNm3ahIEDB4odit27dOkSPDw8sGvXLnTr1k3scOyau7s75s+fj3HjxokdClGNwcpAJSkuLkZ6ejrCwsJMy+RyOcLCwpCWliZiZOQIdDodgLIvOro3g8GAdevWobCwECEhIWKHQ1Sj1BI7AEdx+fJlGAwGaDQas+UajQYnT54UKSpyBEajEZMnT0bXrl3RunVrscOxO0ePHkVISAhu3boFV1dXbNq0CQEBAWKHRVSjMBkgsnNRUVE4duwY9uzZI3YodqlFixbIyMiATqfDhg0bEBkZiV27djEhIKoAJgOVpGHDhlAoFMjNzTVbnpubC61WK1JUVNNFR0djy5YtSE1Nhbe3t9jh2CWlUolmzZoBAIKCgnDgwAEsXrwYK1euFDkyopqDcwYqiVKpRFBQEJKTk03LjEYjkpOTOX5JFSYIAqKjo7Fp0ybs3LkTfn5+YodUYxiNRhQVFYkdBlGNwspAJYqJiUFkZCQ6duyIzp07Y9GiRSgsLMSYMWPEDs1uFBQU4PTp06bHWVlZyMjIgLu7Oxo3bixiZPYlKioKCQkJ+Pbbb+Hm5oacnBwAgFqthouLi8jR2Y+ZM2ciIiICjRs3Rn5+PhISEpCSkoIdO3aIHRpRjcJTCyvZRx99hPnz5yMnJwft2rXDkiVLEBwcLHZYdiMlJQWhoaHllkdGRiI+Pr76A7JTMpnsnstXr16N0aNHV28wdmzcuHFITk7GxYsXoVar0bZtW0yfPh1PPPGE2KER1ShMBoiIiCSOcwaIiIgkjskAERGRxDEZICIikjgmA0RERBLHZICIiEjimAwQERFJHJOBSlZUVITZs2fzCmj3weNkHR4n6/A4WYfHiSzhdQYqmV6vh1qthk6ng0qlEjscu8XjZB0eJ+vwOFmHx4ksYWWAiIhI4pgMEBERSVyNvlGR0WjEX3/9BTc3N4vXcq9uer3e7L90bzxO1uFxsg6Pk3Xs8TgJgoD8/Hx4eXlBLq+636e3bt1CcXGxzftRKpVwdnauhIjsS42eM3DhwgX4+PiIHQYREdkoOzsb3t7eVbLvW7duoZGrCwoMtu9Lq9UiKyvL4RKCGl0ZcHNzAwBMaSqHk9w+KgP2aubuU2KHQERUjj4/Hz7NA02f51WhuLgYBQZgSlMFnGwoPhQZgQ/P5qC4uJjJgD25PTTgJJfBScFk4N+oVFX3h0ZEZKvqGOp1kgPONn1X1NhC+n3V6GSAiIjIWjJZWbNle0fFZICIiCRBDttOoXPk0+8c+bURERGRFVgZICIiSeAwgWVMBoiISBJkfzdbtndUHCYgIiKSOFYGiIhIEjhMYBmTASIikgSeTWCZI782IiIisgIrA0REJAkcJrCMyQAREUkCzyawjMMEREQkCbcrA7a0ioiLi0OnTp3g5uYGDw8PDBw4EJmZmWZ9evToAZlMZtYmTpxo1uf8+fPo168f6tSpAw8PD0ybNg2lpaVmfVJSUtChQwc4OTmhWbNmiI+Pr1CsTAaIiIiqwK5duxAVFYV9+/YhKSkJJSUl6N27NwoLC836jR8/HhcvXjS1efPmmdYZDAb069cPxcXF2Lt3L9asWYP4+HjExsaa+mRlZaFfv34IDQ1FRkYGJk+ejBdeeAE7duywOlYOExARkSRU9zDB9u3bzR7Hx8fDw8MD6enp6Natm2l5nTp1oNVq77mPH374ASdOnMCPP/4IjUaDdu3a4e2338b06dMxe/ZsKJVKrFixAn5+fliwYAEAwN/fH3v27MGHH36I8PBwq2JlZYCIiCRBLrO9AYBerzdrRUVFVj2/TqcDALi7u5stX7t2LRo2bIjWrVtj5syZuHHjhmldWloa2rRpA41GY1oWHh4OvV6P48ePm/qEhYWZ7TM8PBxpaWlWHxtWBoiIiCrAx8fH7PGsWbMwe/bsf93GaDRi8uTJ6Nq1K1q3bm1a/vzzz8PX1xdeXl44cuQIpk+fjszMTGzcuBEAkJOTY5YIADA9zsnJ+dc+er0eN2/ehIuLy31fE5MBIiKShMoaJsjOzoZKpTItd3Jyuu+2UVFROHbsGPbs2WO2fMKECaZ/t2nTBp6enujVqxfOnDmDhx9+2IZoK4bDBEREJAmVdTaBSqUya/dLBqKjo7Flyxb89NNP8Pb2/te+wcHBAIDTp08DALRaLXJzc8363H58e56BpT4qlcqqqgDAZICIiKhKCIKA6OhobNq0CTt37oSfn999t8nIyAAAeHp6AgBCQkJw9OhR5OXlmfokJSVBpVIhICDA1Cc5OdlsP0lJSQgJCbE6ViYDREQkCbJKaBURFRWF//u//0NCQgLc3NyQk5ODnJwc3Lx5EwBw5swZvP3220hPT8e5c+ewefNmjBo1Ct26dUPbtm0BAL1790ZAQABGjhyJX3/9FTt27MAbb7yBqKgoU0Vi4sSJOHv2LF577TWcPHkSH3/8Mb766itMmTLF6liZDBARkSTIZALkNjSZTKjQ8y1fvhw6nQ49evSAp6enqa1fvx4AoFQq8eOPP6J3795o2bIlXn31VQwZMgTfffedaR8KhQJbtmyBQqFASEgIRowYgVGjRmHOnDmmPn5+fti6dSuSkpIQGBiIBQsW4NNPP7X6tEKAEwiJiIiqhCD8e/Lg4+ODXbt23Xc/vr6+2LZt27/26dGjBw4fPlyh+O7GZICIiCSB9yawjMkAERFJApMBy5gMEBGRJPAWxpZxAiEREZHEsTJARESSwGECy5gMEBGRJNx9s6EH3d5RcZiAiIhI4pgM3MPuK0b8749SxP1eivmnS7HuTwMuF5c/XzT7poA12Qa8+3sp4k6VYvX5UpQYy/pdLxHwbY4Bi8+W4p3fS7HkbCl+umyA4a7zTq+XCHgrs7Rcu3CzYhe2qElS9+xF/6HD4fVwa8jqNkLid/9+7qxU8ThZb9nKz9DEvwOc3b0R3D0c+w8eEjsku8TjVP1XIKxJ7CIZWLZsGZo0aQJnZ2cEBwdj//79osbzxw0BnerJMc5XgZHeChgF4P+yDSg23vmSzr4pYO0FAx6uI8MLvgqM91Wgcz256c1yuVgABOBJjRwvNVEg3EOO9OsCki8Zyz3fSG85Xn1YYWqeztX0QkVQWHgDgW1aYdmH74sdil3jcbLO+g2bEDMjFrNmTsWhn5MR2KYVwgc8g7y8S2KHZld4nMpU1o2KHJHoycD69esRExODWbNm4dChQwgMDER4eLjZTRmq2wgfBdqp5fBwkkHrLMMArRy6UuDirTt9duQZ0Lm+DI81KOvXUClDK5Uctf4eVGpWV44Bngo8XFeO+koZWrjKEeIux28F5X/111HI4FrrTlM48DsuIjwMc2e9jkFP9RM7FLvG42SdhUtXYPyYERgz6nkE+LfAiiUfoI6LC1Z9niB2aHaFx4nuR/RkYOHChRg/fjzGjBmDgIAArFixAnXq1MGqVavEDs2k6O8f8y6Ksv8Wlgr48xZQVyHDZ3+U4oPTpYg/X4rzN/69vF9kEOByjyP+5Z8GzD9dilXnS5FZUL5yQETlFRcXI/3wrwgL7W5aJpfLERbaDWn7D4oYmX3hcbqDwwSWiZoMFBcXIz09HWFhYaZlcrkcYWFhSEtLK9e/qKgIer3erFU1QRCwPc8IHxfAw6nsrXCtpGzdrstGdKgnx3BvBbTOMnx+wYAr95hbAABXiwXsvy4gqN6dQ66UAb0byfG0lwLPP6RAYxcZ1v1pZEJAZIXLV67CYDBA49HIbLnGwwM5ueJVFu0Nj9Mdt88msKU5KlGTgcuXL5e9STUas+UajQY5OTnl+sfFxUGtVpuaj49Plce4NdeIvCIBQz0VpmW3v+6D6snQXi2Hp7MMfTwUaFAbOKwr/0WuLxHwfxcMCHCTmSUDdWrJEOIuh7eLDA+5yBDWSIG2Khn2XmUyQERE1Uf0YYKKmDlzJnQ6nallZ2dX6fNtyzXgVKGASB8FVLXvpISuf+cFjZTmaWIjJxn0Jeb7yC8tO+PAx0WG/pr7H+6HnGW4Wmxz6EQOr2EDdygUCuT+YxJcbl4etBoPkaKyPzxOd3CYwDJRk4GGDRuWvUlzc82W5+bmQqvVluvv5OQElUpl1qqCIAjYlmvAyQIBo3wUqP+PL/16tQG3WsDlEvMhgSvFAtS17zzWlwiIP2+A19+TEGVWTAzMKRLgyktBEd2XUqlEUPtAJKekmpYZjUYkp+xGSOeOIkZmX3ic7uDZBJaJ+rWjVCoRFBSE5ORkDBw4EMDfb9LkZERHR4sW17Y8I47qBQx7SAEnOVBQWval7yQHastlkMlkeLS+HClXjNA6GaF1kiFDb8TlYuBpr7L8Sl9SVhFQ15bhiUZy3DAAtwcYXGuVvaMydEYoZIDn33MRfisQkKET0F9bowo2FVJQUIDTZ7JMj7POnUfGr0fh7l4fjX28RYzMvvA4WSdm0kRETpiEju3boXPHDli0bCUKb9zAmJHPiR2aXeFxKsPLEVsm+m/QmJgYREZGomPHjujcuTMWLVqEwsJCjBkzRrSYDl4v+9Jek20wWz5AK0c7ddnboYu7HKUCsCPPiJsGQOMEjPRWwP3vKsLZGwKulgBXSwR8eNZ8P7Na3DnsqVeM0JWUTUxpqASGeskR4Oa4ycDBQ78iNGKg6XHMjDcBAJHDn0X8Jx+JFJX94XGyzrNDB+HS5SuInfs+cnLz0K5ta2xPXA+NxMrf98PjRPcjEwRB9MvdffTRR5g/fz5ycnLQrl07LFmyBMHBwffdTq/XQ61WY0YzBZwUjpyz2W72oYtih0BEVI5enw+1Z1PodLoqG/q9/V2xsoMcLjZ8V9w0CPjPIWOVxioW0SsDABAdHS3qsAARETk+GWybKOfIPzkdtx5NREREVrGLygAREVFVs/WMAJ5NQEREVMPxbALLOExAREQkcawMEBGRJMhh2/0FHPnXM5MBIiKSBA4TWObIiQ4RERFZgZUBIiKSBFtvQ+zItzBmMkBERJIgh23lcEcupTMZICIiSeB1Bixz5ESHiIiIrMDKABERSQKHCSxjMkBERJLAYQLLHDnRISIiIiuwMkBERJIglwk2nlooVF4wdobJABERSQLnDFjmyK+NiIiIrMDKABERSQInEFrGZICIiCRBBtvK4Q6cC3CYgIiISOpYGSAiIkngMIFlTAaIiEgSeDaBZUwGiIhIEngLY8scOdEhIiIiK7AyQEREksA5A5YxGSAiIkngnAHLHPm1ERERkRVYGSAiIkngMIFlTAaIiEgSOExgmSO/NiIiIrKCQ1QGZu4+BZXKTeww7FrBG+3FDqFGcJ17WOwQagRBMIodQo0gk/H3lj3hdQYsc4hkgIiI6H5ksO1mQw6cC3CYgIiISOpYGSAiIkngMIFlTAaIiEgyHPj73CZMBoiISBJYGbCMcwaIiIgkjpUBIiKSBLlMsLEyIFReMHaGyQAREUkCTy20jMMEREREEsdkgIiIJOH2BEJbWkXExcWhU6dOcHNzg4eHBwYOHIjMzEyzPrdu3UJUVBQaNGgAV1dXDBkyBLm5uWZ9zp8/j379+qFOnTrw8PDAtGnTUFpaatYnJSUFHTp0gJOTE5o1a4b4+PiKHZuKvTQiIqKaSVYJrSJ27dqFqKgo7Nu3D0lJSSgpKUHv3r1RWFho6jNlyhR89913+Prrr7Fr1y789ddfGDx4sGm9wWBAv379UFxcjL1792LNmjWIj49HbGysqU9WVhb69euH0NBQZGRkYPLkyXjhhRewY8cO64+NIAg1dkaEXq+HWq2G7uJZ3pvgPnhvAuvw3gTW4b0JrMN7E9yfXp8PtWdT6HQ6qFSqKnqOsu+Kn0MB11oPPvJfUCqg60944FgvXboEDw8P7Nq1C926dYNOp0OjRo2QkJCAoUOHAgBOnjwJf39/pKWloUuXLvj+++/x5JNP4q+//oJGowEArFixAtOnT8elS5egVCoxffp0bN26FceOHTM917Bhw3D9+nVs377dqtj4TiUiIkmorGECvV5v1oqKiqx6fp1OBwBwd3cHAKSnp6OkpARhYWGmPi1btkTjxo2RlpYGAEhLS0ObNm1MiQAAhIeHQ6/X4/jx46Y+d+/jdp/b+7Dq2Fjdk4iIqAaTV0IDAB8fH6jValOLi4u773MbjUZMnjwZXbt2RevWrQEAOTk5UCqVqFevnllfjUaDnJwcU5+7E4Hb62+v+7c+er0eN2/evG9sAE8tJCIiiZDJypot2wNAdna22TCBk5PTfbeNiorCsWPHsGfPngcPoAqxMkBERFQBKpXKrN0vGYiOjsaWLVvw008/wdvb27Rcq9WiuLgY169fN+ufm5sLrVZr6vPPswtuP75fH5VKBRcXF6teE5MBIiKShOo+tVAQBERHR2PTpk3YuXMn/Pz8zNYHBQWhdu3aSE5ONi3LzMzE+fPnERISAgAICQnB0aNHkZeXZ+qTlJQElUqFgIAAU5+793G7z+19WIPDBEREJAnVfQXCqKgoJCQk4Ntvv4Wbm5tpjF+tVsPFxQVqtRrjxo1DTEwM3N3doVKpMGnSJISEhKBLly4AgN69eyMgIAAjR47EvHnzkJOTgzfeeANRUVGmisTEiRPx0Ucf4bXXXsPYsWOxc+dOfPXVV9i6davVsbIyQEREVAWWL18OnU6HHj16wNPT09TWr19v6vPhhx/iySefxJAhQ9CtWzdotVps3LjRtF6hUGDLli1QKBQICQnBiBEjMGrUKMyZM8fUx8/PD1u3bkVSUhICAwOxYMECfPrppwgPD7c6Vl5nQCJ4nQHr8DoD1uF1BqzD6wzcX3VeZ+BQmAyutW24zkCJgA4/ClUaq1g4TEBERNJg49kEjnynIqatREREEsfKABERSYPNFxoAgBo7sv6vmAwQEZEkVNZFhxwRhwmIiIgkjpUBIiKSBJlMBpkNP+8duTLAZICIiCSByYBlTAaIiEga7r714INu76Ac+KURERGRNVgZICIiSeAwgWVMBoiISBJ4aqFlHCaoZMtWfoYm/h3g7O6N4O7h2H/wkNghVZk9F4rwdOJlPPLJX3D78AK+O33TbP1/dlyF24cXzNqgjZfK7Wf72ZsI/TIXjZZcgM/Hf2LY5stm66f9dB2Pr81FgyUX8Oj/5Zbb3tG998FiyOo2wuRp/xU7FFHFfbAYnbuFQ6VtCk2TAAwaFonM30+b9QntMwhyV41Zm/jyNJEiti9S+myiihM1GUhNTUX//v3h5eUFmUyGxMREMcOx2foNmxAzIxazZk7FoZ+TEdimFcIHPIO8vPJfgI7gRokRbRrVxoKe9S32eaKJE05P8DS1VX0bmK3/9tQNTNh+FSMC6mLvSA2SnvXAMy3qlNvPyFZ1MaR5+eWO7kD6Yaxc9Tnatm4ldiiiS92ThpcmjEHazm344buvUVJSivABz6KwsNCs3wujR+CvM0dNbd7cWJEith9S+2yy5PYwgS3NUYmaDBQWFiIwMBDLli0TM4xKs3DpCowfMwJjRj2PAP8WWLHkA9RxccGqzxPEDq1K9PZzQWxXNZ5q5mKxj1Ihg6auwtTqO995y5UaBbyWosPb3ephXKArHqlfGy0b1MbgfyQD80PrYUI7VzRRK6rstdijgoICDB87Ef/7aCHq11eLHY7ovk9ch9EjhqFVQEsEtmmF1SsW43z2BaQfPmLWr04dF2g1HqbGO5pK77PJIlklNAclajIQERGBuXPnYtCgQWKGUSmKi4uRfvhXhIV2Ny2Ty+UIC+2GtP0HRYxMXHsuFMFvxV9oH5+DycnXcOWmwbQuI68EfxUYIJcBXf8vF81W/oXBmy7hxOUSESO2H1FTpqNf+BMI69n9/p0lSKfPBwC4169ntjxh/UY0auyPNp26Yeasubhx44YI0dkPfjaRNWrUBMKioiIUFRWZHuv1ehGjMXf5ylUYDAZoPBqZLdd4eODkP8Y1peKJJs54qpkLmqhr4ez1Urz1sw5DNl1G8jAPKOQynNOVAgDi0vSI665GY1UtLE3PR8TXl3B4jBbuztKd0rLu6004lHEUB3b/IHYodsloNGLK9DfQNaQzWrfyNy1/7plB8G3sAy+tBkeOn8CMN+fi99/P4JsvV4sYrbj42XQHzyawrEYlA3FxcXjrrbfEDoOsNPSucn+rhrXRumFttF2dg90XitCjsTOMf9/8a2pnNwx4pKzv8t7uaPHpRST+fgNj27qKEbbosi/8iVem/RdJ330NZ2dnscOxS1FTZuDYiUzsTtpstnzC2FGmf7dpHQBPjQZhTw7FmbPn8HDTJtUcJdkbnk1gWY366TVz5kzodDpTy87OFjskk4YN3KFQKJD7jwk5uXl50Go8RIrKvvjVq4UGLnKcvV5WEdDWLXv7tWxQ29THqZYMfmoFsvMN99yHFKQf/hV5ly6hQ9deqKXSopZKi12792LJ8v+hlkoLg0G6xwYAomNmYuv2JOzc9g28H/L6177BnToAAE6fzaqO0OwSP5vIGjUqGXBycoJKpTJr9kKpVCKofSCSU1JNy4xGI5JTdiOkc0cRI7Mff+aX4upNIzR1yyYCtvNQwkkBnLpWaupTYhDwh94AHzdpTRa8W68e3XB0fyoy0n4ytY4d2mH4s0ORkfYTFAppHhtBEBAdMxOJ321D8tZv4NfE977bZBw5DgDw1Er3S4+fTXfwbALLatQwgb2LmTQRkRMmoWP7dujcsQMWLVuJwhs3MGbkc2KHViUKio2mX/kA8Ie+FEfyilHfWY76znLE7dNjwCMu0NRRIEtXijd369C0Xi2E+ZaVvlVOcoxr64p30/TwdlPAx02Bxellk8IG3XUa4ZnrpSgsNiK30IibpQKO5BUDKKsoKBWO98fp5uZqNg4OAHXr1kED9/rllktJ1JQZ+PLrjUhctwZubq7Iyc0DAKhVbnBxccGZs+eQ8NVG9A3vhQbu9XHk2AnEzIhFt64hkj81U2qfTRbZPE5QeaHYG1GTgYKCApw+fWcCS1ZWFjIyMuDu7o7GjRuLGNmDeXboIFy6fAWxc99HTm4e2rVtje2J66Fx0FLc4dxi9N1w5wJBM3fpAADPB9TBol71cfxyCRJO3ICuyAhPVwV6NnbGm4+q4FTrzl/U3MfVUMiB8duv4lapgI5aJbYOaWR2CmJ00lXsuVBsetx1bdmXwLGxWviqmc9KxYpP4wEAoRHmZx+tWrEYo0cMg1JZG8k/pWLxx5+gsPAGfLy9MHjAk3jjtSkiRGtfpPbZZAnnDFgmEwRBEOvJU1JSEBoaWm55ZGQk4uPj77u9Xq+HWq2G7uJZnkt8HwVvtBc7hBrBde5hsUOoEQTBKHYINYJMVqNGYkWh1+dD7dkUOp2uyoZ+b39XnBzqArfaD/6Nnl8ioOWGm1Uaq1hE/VnVo0cPiJiLEBGRhPDUQstYYyUiIkngMIFlrGERERFJHCsDREQkETaWBhwYkwEiIpIEDhNYxmECIiIiiWNlgIiIJIFnE1jGZICIiCSByYBlHCYgIiKSOFYGiIhIEjiB0DImA0REJA28UZFFTAaIiEgSWBmwjHMGiIiIJI6VASIikgYbzybgMAEREVENx2ECyzhMQEREJHGsDBARkTTwbAKLmAwQEZEk8AqElnGYgIiISOJYGSAiIkngBELLmAwQEZEklCUDtgwTCJUYjX3hMAEREZHEsTJARETSIINtZwRwmICIiKhmk8nlkMkfvCAuc+BaOpMBIiKSBs4gtMiB8xwiIiKyBisDREQkDawMWMRkgIiIJEEGOWQ2DPw7birAYQIiIiLJY2WAiIikgcMEFjEZICIiaWAyYBGTAYmoO+eg2CHUCIJgFDsEIqJqx2SAiIgkwfZbGLMyQEREVLPJ5LZdRtBxcwGeTUBERCR1rAwQEZEkyOQyyOQ2DBPYsK29YzJARETSwLMJLGIyQERE0sA5AxZxzgAREVEVSE1NRf/+/eHl5QWZTIbExESz9aNHjzad4XC79enTx6zP1atXMXz4cKhUKtSrVw/jxo1DQUGBWZ8jR47g8ccfh7OzM3x8fDBv3rwKx8pkgIiIJOGfX7wP0iqisLAQgYGBWLZsmcU+ffr0wcWLF03tyy+/NFs/fPhwHD9+HElJSdiyZQtSU1MxYcIE03q9Xo/evXvD19cX6enpmD9/PmbPno1PPvmkQrFymICIiKShkuYM6PV6s8VOTk5wcnIq1z0iIgIRERH/uksnJydotdp7rvvtt9+wfft2HDhwAB07dgQALF26FH379sUHH3wALy8vrF27FsXFxVi1ahWUSiVatWqFjIwMLFy40CxpuB9WBoiIiCrAx8cHarXa1OLi4h54XykpKfDw8ECLFi3w4osv4sqVK6Z1aWlpqFevnikRAICwsDDI5XL88ssvpj7dunWDUqk09QkPD0dmZiauXbtmdRysDBARkTTIYGNloOw/2dnZUKlUpsX3qgpYo0+fPhg8eDD8/Pxw5swZvP7664iIiEBaWhoUCgVycnLg4eFhtk2tWrXg7u6OnJwcAEBOTg78/PzM+mg0GtO6+vXrWxULkwEiIpIEmUwOmQ1nE8hkAgBApVKZJQMPatiwYaZ/t2nTBm3btsXDDz+MlJQU9OrVy+b9VwSHCYiIiOxA06ZN0bBhQ5w+fRoAoNVqkZeXZ9antLQUV69eNc0z0Gq1yM3NNetz+7GluQj3wmSAiIik4fYEQltaFbpw4QKuXLkCT09PAEBISAiuX7+O9PR0U5+dO3fCaDQiODjY1Cc1NRUlJSWmPklJSWjRooXVQwQAkwEiIpKI25cjtqVVREFBATIyMpCRkQEAyMrKQkZGBs6fP4+CggJMmzYN+/btw7lz55CcnIwBAwagWbNmCA8PBwD4+/ujT58+GD9+PPbv34+ff/4Z0dHRGDZsGLy8vAAAzz//PJRKJcaNG4fjx49j/fr1WLx4MWJiYioUK5MBIiKiKnDw4EG0b98e7du3BwDExMSgffv2iI2NhUKhwJEjR/DUU0+hefPmGDduHIKCgrB7926zCYlr165Fy5Yt0atXL/Tt2xePPfaY2TUE1Go1fvjhB2RlZSEoKAivvvoqYmNjK3RaIQDIBEEQKudlVz+9Xg+1Wg3dxbNQqdzEDseuCUaD2CHUDA587XGqfrZMVpMKvT4fas+m0Ol0lTIp797PUfZdkTe9JVROigffT5EBHu+frNJYxWLV2QSbN2+2eodPPfXUAwdDRERUZXijIousSgYGDhxo1c5kMhkMBv4CJSIi+yNDxS8p/M/tHZVVyYDRaKzqOIiIiEgkvOgQERFJA4cJLHqgZKCwsBC7du3C+fPnUVxcbLbu5ZdfrpTAiIiIKpVMXtYeePsaO9/+viqcDBw+fBh9+/bFjRs3UFhYCHd3d1y+fBl16tSBh4cHkwEiIqIapsIp0pQpU9C/f39cu3YNLi4u2LdvH/744w8EBQXhgw8+qIoYiYiIbCaTyWxujqrCyUBGRgZeffVVyOVyKBQKFBUVwcfHB/PmzcPrr79eFTESERHZTi6zvTmoCicDtWvXhlxetpmHhwfOnz8PoOwqSNnZ2ZUbHREREVW5Cs8ZaN++PQ4cOIBHHnkE3bt3R2xsLC5fvowvvvgCrVu3rooYiYiIbFZZtzB2RBU+Ku+++67pjkrvvPMO6tevjxdffBGXLl0yu14yERGRXbHzuxaKqcKVgY4dO5r+7eHhge3bt1dqQERERFS9eNEhIiKSBl50yKIKJwN+fn7/enrF2bNnbQqIiIioKpTlAjbcm8Bxc4GKzxmYPHkyXnnlFVN76aWXEBISAp1OV+H7JzuaP/+6iBFjX0QDn+ZwaeCDNp264eChDLHDEs3yT+MR2CUUaq9mUHs1w6M9++H7H5IBAFevXsOkqa+jZfuuqNOoCXz9g/DytP9Cp9OLHHX1i/tgMTp3C4dK2xSaJgEYNCwSmb+fNuvzn0lT0axNZ9Rp6AsP3wAMfHYUTmaeEilicVhznEL7DILcVWPWJr48TaSI7cuylZ+hiX8HOLt7I7h7OPYfPCR2SNXv9hUIbWkOqsKVgVdeeeWey5ctW4aDBw9WaF9xcXHYuHEjTp48CRcXFzz66KN4//330aJFi4qGJbpr166ja69+CO3WFd9vWodGDRvg1OmzqF9PLXZoovH28kLcW//FIw83hSAIWJPwFQYOG41DPydBEARcvJiL+e/MQkDL5vgj+wJefOU1XLyYg6//7zOxQ69WqXvS8NKEMejUoR1KDQb8d/a7CB/wLI4fTEXdunUBAEHt22L4s0PQ2OchXL12HW+9Ox/hA57F2eMHoFA8+P3ZaxJrjhMAvDB6BOa8Od30uI6Lixjh2pX1GzYhZkYsViyej+BOQVi0bCXCBzyDzMNp8PBoJHZ4ZAdkgiBUyrkSZ8+eRbt27aDXW//Lrk+fPhg2bBg6deqE0tJSvP766zh27BhOnDhh9sdtiV6vh1qthu7iWahUbraEb7MZb87Bz/v2Y3fSFlHjsEQw2setpRs0bol5b8diXOTz5dZ9vWkzRr4QjYLcs6hVS6TpLHZQB7x06TI0fq2Qsj0R3R4LuWefI8eOo12Xnjh15Bc83LRJ9QZoJ+51nEL7DEJg21ZYNG+uyNGVseU0tsoU3D0cnYLa4aOF7wMouxOtT/NATJr4AmZMvfcPvOqi1+dD7dkUOp0OKpWqip6j7Lvi6tudoXJ+8M8W/a1SuL+5v0pjFUulvVM3bNgAd3f3Cm2zfft2jB49Gq1atUJgYCDi4+Nx/vx5pKenV1ZY1Wbzth3o2L4dnh4xFh6+/mgfEor/rf5C7LDshsFgwLoNiSgsvIGQ4KB79tHp8qFycxUvEbATOn0+AMC9fr17ri8sLMTqL9bBr0lj+Hh7VWNk9sXScUpYvxGNGvujTadumDlrLm7cuCFCdPajuLgY6Yd/RVhod9MyuVyOsNBuSNtfsWpuTcfLEVv2QBcduvuACIKAnJwcXLp0CR9//LFNweh0OgCwmFQUFRWhqKjI9LgiVYiqdjbrDyz/NB4xkybi9amTceBQBl6e+jqUtWsjcsQwscMTzdHjv+HRXv1w61YRXF3rYmPCKgS0LD8MdPnyFcydtxDjx4wUIUr7YTQaMWX6G+ga0hmtW/mbrfv4k9WY/uYcFBbeQItHmuGHzV9DqVSKFKm4LB2n554ZBN/GPvDSanDk+AnMeHMufv/9DL75crWI0Yrr8pWrMBgM0PxjOEDj4YGT/5hzQdJV4WRgwIABZsmAXC5Ho0aN0KNHD7Rs2fKBAzEajZg8eTK6du1q8UqGcXFxeOuttx74OaqS0WhExw7t8O5bbwAA2rdri2MnfsOKz9ZIOhlo8cjDOPxzMnR6PTYkbsHo/7yMlO2bzBICvT4fTz49AgEtm2P261NFjFZ8UVNm4NiJTOxO2lxu3fBnh+CJnt1xMScXC5Z8jGdHjceeH7+Ds7OzCJGKy9JxmjB2lOnfbVoHwFOjQdiTQ3Hm7DnJDqfQXeTysmbL9g6qwsnA7NmzqyAMICoqCseOHcOePXss9pk5cyZiYmJMj/V6PXx8fKoknory1GoQ0LK52TL/Fs3xTaJ9ziGoLkqlEs0e9gMABLUPxMFDGVj88adYuWQ+ACA/vwARg56Dm6srNiasRu3atcUMV1TRMTOxdXsSdu1IhPdD5cv/arUKarUKjzRrii6dg+Du3RybNm/Dc88MFiFa8dzvON0tuFMHAMDps1mSTQYaNnCHQqFAbt4ls+W5eXnQajxEikokvM6ARRVOcxQKBfLy8sotv3LlygPPao6OjsaWLVvw008/wdvb22I/JycnqFQqs2YvunbpjMxT5iW330+dgW9j+0hW7IXRaETx30M9en0+wgc8C6WyNr5dv0aSv3CBsqG26JiZSPxuG5K3fgO/Jr5WbSMIQFFxcTVEaB8e5DhlHDkOAPDUSuxL7y5KpRJB7QORnJJqWmY0GpGcshshnTv+y5YkJRWuDFg6+aCoqKjC45eCIGDSpEnYtGkTUlJS4OfnV9Fw7MaUSRPxaM++eHf+h3hm8ADsP3gYn6z+Ap8sXSB2aKKZOesdRDzRE419HkJ+QSESvtqIlN17sT1xnSkRuHHzJr74dBn0+QXQ5xcAABo1bCCZ0+WAspL3l19vROK6NXBzc0VOblmyrVa5wcXFBWezzmH9N9+id68eaNSwAS78eRHvL1wCFxdn9O3dS+Toq8/9jtOZs+eQ8NVG9A3vhQbu9XHk2AnEzIhFt64haNu6lcjRiytm0kRETpiEju3boXPHDli0bCUKb9zAmJHPiR1a9bL1WgF2cnZIVbA6GViyZAmAstmYn376KVxdXU3rDAYDUlNTKzxnICoqCgkJCfj222/h5uaGnJwcAGW3Q3apYecGdwpqj03r1mBm7FzMiVsAvyaNsWjeXAwfNlTs0ESTd+kyIv8zCRdz8qBWuaFt6wBsT1yHJ3p2R8run/HL3xc9eSSwi9l2Z4/tRxPfxmKELIoVn8YDAEIjBpktX7ViMUaPGAZnZ2fs2fsLFi/7BNeu66DxaIRuXbvg5x+3SOoc8fsdJ6WyNpJ/SsXijz9BYeEN+Hh7YfCAJ/HGa1NEiNa+PDt0EC5dvoLYue8jJzcP7dq2xvbE9dBwmKDi2zsoq68zcPtX+x9//AFvb2+zX25KpRJNmjTBnDlzEBwcbP2TWziwq1evxujRo++7vT1dZ8De2ct1BuyeA/+xU/Wzl+sM2LPqvM7Atfcft/k6A/Wn73bI6wxYfVSysrIAAKGhodi4cSPq169v85NX0vWOiIiIrGDrJYUdN7mrcIr0008/VUUcREREVYvDBBZVOM0ZMmQI3n///XLL582bh6effrpSgiIiIqp0vFGRRRV+Zampqejbt2+55REREUhNTb3HFkRERGTPKjxMUFBQcM9TCGvXrm1XlwcmIiIyw2ECiypcGWjTpg3Wr19fbvm6desQEBBQKUERERFVOpnMxmECx00GKlwZePPNNzF48GCcOXMGPXv2BAAkJycjISEBGzZsqPQAiYiIqGpVOBno378/EhMT8e6772LDhg1wcXFBYGAgdu7cWeFbGBMREVUbDhNY9EBXX+jXrx/69esHoOxiDl9++SWmTp2K9PR0GAy8uA0REdkhJgMWPfB5EqmpqYiMjISXlxcWLFiAnj17Yt++fZUZGxEREVWDClUGcnJyEB8fj88++wx6vR7PPPMMioqKkJiYyMmDRERk33ijIousfmX9+/dHixYtcOTIESxatAh//fUXli5dWpWxERERVZ7bwwS2NAdldWXg+++/x8svv4wXX3wRjzzySFXGRERERNXI6srAnj17kJ+fj6CgIAQHB+Ojjz7C5cuXqzI2IiKiysPLEVtk9Svr0qUL/ve//+HixYv4z3/+g3Xr1sHLywtGoxFJSUnIz8+vyjiJiIhsw2ECiyqc5tStWxdjx47Fnj17cPToUbz66qt477334OHhgaeeeqoqYiQiIrIdKwMW2fTKWrRogXnz5uHChQv48ssvKysmIiIiqkYPdNGhf1IoFBg4cCAGDhxYGbsjIiKqfLzokEWVkgwQERHZPV5nwCLHfWVERERkFVYGiIhIGjhMYBGTASIikgYOE1jkuK+MiIiIrMLKABERSQOHCSxiMkBERNIgk9k4TOC4yQCHCYiIiCSOlQEiIpIIW+8v4LiVASYDREQkDTybwCImA0REJA2cQGiR46Y5REREZBVWBoiISBo4TGARkwGpMJaIHUGNIKvlLHYINYJQekvsEGoGvp/sC4cJLHLcNIeIiIiswsoAERFJA4cJLHLcV0ZERHQ3ucz2VgGpqano378/vLy8IJPJkJiYaLZeEATExsbC09MTLi4uCAsLw6lTp8z6XL16FcOHD4dKpUK9evUwbtw4FBQUmPU5cuQIHn/8cTg7O8PHxwfz5s2r+KGp8BZERER0X4WFhQgMDMSyZcvuuX7evHlYsmQJVqxYgV9++QV169ZFeHg4bt26Mydn+PDhOH78OJKSkrBlyxakpqZiwoQJpvV6vR69e/eGr68v0tPTMX/+fMyePRuffPJJhWLlMAEREUlDNU8gjIiIQERExD3XCYKARYsW4Y033sCAAQMAAJ9//jk0Gg0SExMxbNgw/Pbbb9i+fTsOHDiAjh07AgCWLl2Kvn374oMPPoCXlxfWrl2L4uJirFq1CkqlEq1atUJGRgYWLlxoljTcDysDREQkDbfnDNjSUPZr/O5WVFRU4VCysrKQk5ODsLAw0zK1Wo3g4GCkpaUBANLS0lCvXj1TIgAAYWFhkMvl+OWXX0x9unXrBqVSaeoTHh6OzMxMXLt2zep4mAwQERFVgI+PD9RqtanFxcVVeB85OTkAAI1GY7Zco9GY1uXk5MDDw8Nsfa1ateDu7m7W5177uPs5rMFhAiIikoZKGibIzs6GSqUyLXZycrI1MtGxMkBERNJQScMEKpXKrD1IMqDVagEAubm5Zstzc3NN67RaLfLy8szWl5aW4urVq2Z97rWPu5/DGkwGiIhIGmQyG5OByrsCoZ+fH7RaLZKTk03L9Ho9fvnlF4SEhAAAQkJCcP36daSnp5v67Ny5E0ajEcHBwaY+qampKCm5c5XZpKQktGjRAvXr17c6HiYDREREVaCgoAAZGRnIyMgAUDZpMCMjA+fPn4dMJsPkyZMxd+5cbN68GUePHsWoUaPg5eWFgQMHAgD8/f3Rp08fjB8/Hvv378fPP/+M6OhoDBs2DF5eXgCA559/HkqlEuPGjcPx48exfv16LF68GDExMRWKlXMGiIhIGqr5CoQHDx5EaGio6fHtL+jIyEjEx8fjtddeQ2FhISZMmIDr16/jsccew/bt2+HsfOeeFmvXrkV0dDR69eoFuVyOIUOGYMmSJab1arUaP/zwA6KiohAUFISGDRsiNja2QqcVAoBMEAShQlvYEb1eD7VaDd3Fs1Cp3MQOx67xxjLW4Y2KrMP3k3X4fro/vT4fas+m0Ol0ZpPyKvc5yr4rrq17Cao6Dz7ZT3+jCPWHfVylsYqFwwREREQSx2ECIiKSBt6oyCImA0REJA1MBixy3FdGREREVmFlgIiIpKGab1RUkzAZICIiaeAwgUWO+8qIiIjIKqwMEBGRRNhYGXDg389MBoiISBo4TGARkwEiIpIGTiC0yHHTHCIiIrIKKwNERCQNHCawiMkAERFJg0xmYzLAYQIiIiJyUKwMEBGRNMjlZc2W7R0UkwEiIpIGnk1gkeOmOURERGQVJgOVJHXPXvQfOhxeD7eGrG4jJH63TeyQRGcwGPDm3Plo2uZR1NE0Q7PArnh73iIIgmDqI1f73LPNX7xCxMjFFzd/ETo9/gTcNE3g4euPgc+OQubvp8UOS1TWvJ/GvDil3HspYvAIEaO2H8tWfoYm/h3g7O6N4O7h2H/wkNghVb/bZxPY0hwUhwkqSWHhDQS2aYWxo57H4OdGix2OXXj/w4+x4rMvEL/iQ7Rq2RwHDx/B2KhXoVap8PLEsQCAv35PN9vm+6Sf8EL0NAx5KkKMkO3Grj17ETVhLDoFtUdpaSlen/0Oej/1NE6k70HdunXFDk8U1ryfAKBPWA+s+niB6bGTUilGuHZl/YZNiJkRixWL5yO4UxAWLVuJ8AHPIPNwGjw8GokdXvXhqYUWiZoMLF++HMuXL8e5c+cAAK1atUJsbCwiImreF0FEeBgiwsPEDsOupO1Px1N9e6NfeC8AQBNfH6zb8C0OpGeY+mg1HmbbbN72A0IffxRN/XyrM1S7s/3br8wex69cCo8m/kg//Cu6PfaoSFGJy5r3EwA4OSnLva+kbuHSFRg/ZgTGjHoeALBiyQfYuj0Jqz5PwIypr4gcHdkDUdMcb29vvPfee0hPT8fBgwfRs2dPDBgwAMePHxczLKokIZ2DsDP1Z/x++iwA4NejJ7Bn3wH0eSL0nv1z8y5h646dGDvq2eoMs0bQ6fUAAPf69UWORDzWvp9S9uyD5uF2aBnUHS9OmYkrV6+JEa7dKC4uRvrhXxEW2t20TC6XIyy0G9L2HxQxMhHcnkBoS3NQolYG+vfvb/b4nXfewfLly7Fv3z60atVKpKiossyIiYI+vwD+HXtAoVDAYDBg7puvYfgzg+7Zf03CBri51sXg/jWvMlSVjEYjJr/2BrqGdEbrVv5ihyMaa95P4b16YFD/CPj5+uBM1h/475x56DtkJPb++C0UCoWI0Yvn8pWrMBgM0PxjOEDj4YGTUpuHwmECi+xmzoDBYMDXX3+NwsJChISE3LNPUVERioqKTI/1f/9aIvv01cbvkPD1Jqz9dCla+TdHxtETmDJjNrw8NYh8/uly/Vf/33o8/8wgODs7ixCt/YqaMh3HTpzEnh+3iB2KqKx5Pw0bOsDUv00rf7Rt5Y9m7R5Dyu409OrxmFihk71gMmCR6MnA0aNHERISglu3bsHV1RWbNm1CQEDAPfvGxcXhrbfequYI6UG9FvsOpk95yfQB3aaVP/7IvoD3Fi4rlwzs3vsLMk+dwbrVH4sRqt2KjpmOLd//gNQfNsP7IS+xwxFVRd5PtzX180XDBu44ffacZJOBhg3coVAokJt3yWx5bl4e51aQiehpTosWLZCRkYFffvkFL774IiIjI3HixIl79p05cyZ0Op2pZWdnV3O0VBE3btyE/B+ZtEKugNFoLNd31RfrENSuDQLb3DsRlBpBEBAdMx2bNm/Dzm0b4ddE2hMqgYq9n2678OdFXLl6DZ5a6X7pKZVKBLUPRHJKqmmZ0WhEcspuhHTuKGJkIuCphRaJXhlQKpVo1qwZACAoKAgHDhzA4sWLsXLlynJ9nZyc4OTkVN0hWqWgoACnz2SZHmedO4+MX4/C3b0+Gvt4ixiZePpHhOHdBUvR2OchtGrZHIePHMOHy/6HMSPMJwjq9fn4OnErPpj7pkiR2p+oKdOR8NU3+Hb953BzdUVOTi4AQK1WwcXFReToxHG/91NBQSHeeu9DDBnQF1qPRjiT9Qemx76LZk2bILxX9/vs3bHFTJqIyAmT0LF9O3Tu2AGLlq1E4Y0bGDPyObFDq168AqFFoicD/2Q0Gs3mBdQUBw/9itCIgabHMTPKvtgihz+L+E8+EikqcS2Z9zbefOcDRL36X+RdugwvrQYTxgxH7PTJZv3WfbMZgiDgubvGe6Vu+f9WAwB69Blotnz1iiUYLbUP8L/d7/2kUMhx9Phv+PzLDbiu08PLU4MnQrvh7Tem2u2PiOry7NBBuHT5CmLnvo+c3Dy0a9sa2xPXQ8NhAvqbTLj78l3VbObMmYiIiEDjxo2Rn5+PhIQEvP/++9ixYweeeOKJ+26v1+uhVquhu3gWKpVbNURccwmlt8QOoUaQ1eLkRWvw/WQdvp/uT6/Ph9qzKXQ6HVQqVRU9R9l3xbWk96Gq++CVNX3hTdR/YnqVxioWUSsDeXl5GDVqFC5evAi1Wo22bdtanQgQERFVCM8msEjUZOCzzz4T8+mJiIgIdjhngIiIqEpwAqFFTAaIiEgibD090HGHCRz3lREREZFVWBkgIiJp4ARCi5gMEBGRNDAZsIjJABERSYNcVtZs2d5BOW6aQ0RERFZhZYCIiKSBwwQWMRkgIiJpYDJgkeO+MiIiIrIKKwNERCQNrAxYxGSAiIikgZcjtshx0xwiIiKyCisDREQkIY77694WTAaIiEgaOGfAIsd9ZURERGQVVgaIiEgaOIHQIiYDREQkEXLYVhB33GI6kwEiIpIGVgYsctw0h4iIiKzCygAREUkDKwMWMRkgIiKJ4JwBSxz3lREREZFVWBkgIiJp4DCBRUwGiIhIGpgMWMRhAiIiIoljZYCIiCSCEwgtYTJARETSwGECixw3zSEiIiKrMBkgIiJpuH0LY1taBcyePRsymcystWzZ0rT+1q1biIqKQoMGDeDq6oohQ4YgNzfXbB/nz59Hv379UKdOHXh4eGDatGkoLS2tlMNxNw4TSISslrPYIZAD4fuJaibZ382W7SumVatW+PHHH02Pa9W687U7ZcoUbN26FV9//TXUajWio6MxePBg/PzzzwAAg8GAfv36QavVYu/evbh48SJGjRqF2rVr491337XhdZTHZICIiKRBhDkDtWrVglarLbdcp9Phs88+Q0JCAnr27AkAWL16Nfz9/bFv3z506dIFP/zwA06cOIEff/wRGo0G7dq1w9tvv43p06dj9uzZUCqVD/5a/oHDBERERBWg1+vNWlFRkcW+p06dgpeXF5o2bYrhw4fj/PnzAID09HSUlJQgLCzM1Ldly5Zo3Lgx0tLSAABpaWlo06YNNBqNqU94eDj0ej2OHz9eqa+JyQAREUmEzMb5AmWVAR8fH6jValOLi4u757MFBwcjPj4e27dvx/Lly5GVlYXHH38c+fn5yMnJgVKpRL169cy20Wg0yMnJAQDk5OSYJQK3199eV5k4TEBERJJwexKfLdsDQHZ2NlQqlWm5k5PTPftHRESY/t22bVsEBwfD19cXX331FVxcXB44jqrAygAREVEFqFQqs2YpGfinevXqoXnz5jh9+jS0Wi2Ki4tx/fp1sz65ubmmOQZarbbc2QW3H99rHoItmAwQEZFEyCuhPbiCggKcOXMGnp6eCAoKQu3atZGcnGxan5mZifPnzyMkJAQAEBISgqNHjyIvL8/UJykpCSqVCgEBATbF8k8cJiAiImmo5rMJpk6div79+8PX1xd//fUXZs2aBYVCgeeeew5qtRrjxo1DTEwM3N3doVKpMGnSJISEhKBLly4AgN69eyMgIAAjR47EvHnzkJOTgzfeeANRUVFWVyOsxWSAiIioCly4cAHPPfccrly5gkaNGuGxxx7Dvn370KhRIwDAhx9+CLlcjiFDhqCoqAjh4eH4+OOPTdsrFAps2bIFL774IkJCQlC3bl1ERkZizpw5lR6rTBAEodL3Wk30ej3UajV0F89CpXITOxwiIqogvT4fas+m0Ol0ZpPyKvc5yr4rrv+6GSq3ug++n/xC1At8qkpjFQsrA0REJBG8a6EljvvKiIiIyCqsDBARkTTwFsYWMRkgIiJpYDJgEZMBIiKSCM4ZsMRxXxkRERFZhZUBIiKSBg4TWMRkgIiIpMF090EbtndQjvvKiIiIyCqsDBARkUTI/m62bO+YmAwQEZE0cM6ARRwmICIikjhWBoiISBpkMhsnEDpuZYDJABERSQOHCSxiMkBERBLBCYSWcM4AERGRxLEyQERE0sCLDlnEZICIiCSCwwSWOG6aQ0RERFZhZYCIiKSBZxNYxGSAiIgkgsMElnCYoAq898FiyOo2wuRp/xU7FLtjMBjw5pw4+AUEwaWBDx5u3Qlvv7cAgiCIHZrd+fOvixgx9kU08GkOlwY+aNOpGw4eyhA7LLvFv7t/t2zlZ2ji3wHO7t4I7h6O/QcPiR0S2RFWBirZgfTDWLnqc7Rt3UrsUOzS+wuXYPmn8VjzyVK08m+Jg4cyMGbiy1Cr3PDySxPEDs9uXLt2HV179UNot674ftM6NGrYAKdOn0X9emqxQ7NL/Lv7d+s3bELMjFisWDwfwZ2CsGjZSoQPeAaZh9Pg4dFI7PCqD4cJLGJloBIVFBRg+NiJ+N9HC1G/Pj+072XvvgMY0K8P+vXpjSa+jTF00FPo3asH9h88LHZoduX9hUvg4+2F1SuXonPHDvBr4oveYaF4uKmf2KHZHf7d3d/CpSswfswIjBn1PAL8W2DFkg9Qx8UFqz5PEDs0shNMBipR1JTp6Bf+BMJ6dhc7FLv1aJdOSE7Zjd9PnQEA/HrkGPbs3Y+I3r1Ejsy+bN62Ax3bt8PTI8bCw9cf7UNC8b/VX4gdll3i392/Ky4uRvrhXxEWeuf4yOVyhIV2Q9r+gyJGRvaEwwSVZN3Xm3Ao4ygO7P5B7FDs2oxXX4Fen4+W7UOgUChgMBjwzqzXMXzYULFDsytns/7A8k/jETNpIl6fOhkHDmXg5amvQ1m7NiJHDBM7PLvBv7v7u3zlKgwGAzT/GA7QeHjg5O+nRYpKJBwmsKhGJQNFRUUoKioyPdbr9SJGc0f2hT/xyrT/Ium7r+Hs7Cx2OHbtq2++xdr13yBh9Uq08m+BjCPHMHn6G/Dy1PJL7i5GoxEdO7TDu2+9AQBo364tjp34DSs+W8Pj9Df+3VHF8WwCS2pUMhAXF4e33npL7DDKST/8K/IuXUKHrndK3QaDAal70vDRys9QdO1PKBQKESO0H9P+OxszXn0Zw54eBABo0zoAf2RnI27BYn7J3cVTq0FAy+Zmy/xbNMc3iVtEisj+8O/OOg0buEOhUCA375LZ8ty8PGg1HiJFJRJWBiyqUcnAzJkzERMTY3qs1+vh4+MjYkRlevXohqP7U82WjZn4Mlo2fwTTYybxA+kuN27ehFxuPlVFIVfAaDSKFJF96tqlMzJPmZdwfz91Br6NxX+/2wv+3VlHqVQiqH0gklNSMbB/XwBllafklN2I/s84kaMje1GjkgEnJyc4OTmJHUY5bm6uaN3K32xZ3bp10MC9frnlUtc/ojfemfchGvs8hFb+LXH416NY+NEKjB35vNih2ZUpkybi0Z598e78D/HM4AHYf/AwPln9BT5ZukDs0OwG/+6sFzNpIiInTELH9u3QuWMHLFq2EoU3bmDMyOfEDq2acZjAkhqVDFDNt3TBe3hzThxemjwdeZcuw8tTi/+MHYXYmVPFDs2udApqj03r1mBm7FzMiVsAvyaNsWjeXE60pAfy7NBBuHT5CmLnvo+c3Dy0a9sa2xPXQ8Nhgopv76BkQg2+9Jter4darYbu4lmoVG5ih0NERBWk1+dD7dkUOp0OKpWqip6j7Lvi+tkDULm5Pvh+8gtQr2mnKo1VLKwMEBGRRHCYwBImA0REJA0cJrCIVyAkIiKSOFYGiIhIIjhMYAmTASIikg4HLvXbgsMEREREEsfKABERSQSHCSxhZYCIiEjiWBkgIiJJkMlkkNkwZ8CWbe0dKwNEREQSx8oAERFJBOcMWMJkgIiIpIFXILSIwwREREQSx8oAERFJBIcJLGEyQERE0sBhAos4TEBERCRxrAwQEZFEcJjAEiYDREQkDRwmsIjDBERERBLHygAREUkEhwksYTJARETSwGECi5gMEBGRRLAyYAnnDBAREUkcKwNERCQNLAxYxGSAiIgkgtmAJRwmICIikjhWBoiISBp4NoFFTAaIiEgiOExgCYcJiIiIqtCyZcvQpEkTODs7Izg4GPv37xc7pHKYDBARkTTcHiawpVXQ+vXrERMTg1mzZuHQoUMIDAxEeHg48vLyquAFPjgmA0REJBGySmgVs3DhQowfPx5jxoxBQEAAVqxYgTp16mDVqlWV8HoqT42eMyAIAgBAn58vciRERPQgbn9+3/48r47nsnV7vV5vttzJyQlOTk7l+hcXFyM9PR0zZ840LZPL5QgLC0NaWppNsVS2Gp0M5P/9P8aneaDIkRARkS3y8/OhVqurZN9KpRJarbZSvitcXV3h4+NjtmzWrFmYPXt2ub6XL1+GwWCARqMxW67RaHDy5EmbY6lMNToZ8PLyQnZ2Ntzc3CCzk1M+9Ho9fHx8kJ2dDZVKJXY4dovHyTo8TtbhcbKOPR4nQRCQn58PLy+vKnsOZ2dnZGVlobi42OZ9CYJQ7vvmXlWBmqZGJwNyuRze3t5ih3FPKpXKbv7Y7BmPk3V4nKzD42QdeztOVVURuJuzszOcnZ2r/Hnu1rBhQygUCuTm5potz83NhVarrdZY7ocTCImIiKqAUqlEUFAQkpOTTcuMRiOSk5MREhIiYmTl1ejKABERkT2LiYlBZGQkOnbsiM6dO2PRokUoLCzEmDFjxA7NDJOBSubk5IRZs2Y5xBhSVeJxsg6Pk3V4nKzD41T9nn32WVy6dAmxsbHIyclBu3btsH379nKTCsUmE6rjfA4iIiKyW5wzQEREJHFMBoiIiCSOyQAREZHEMRkgIiKSOCYDRHZk9OjRGDhwoOlxjx49MHny5GqPIyUlBTKZDNevX6/25yai6sdkgMgKo0ePhkwmg0wmg1KpRLNmzTBnzhyUlpZW6fNu3LgRb7/9tlV9+QVORA+K1xkgslKfPn2wevVqFBUVYdu2bYiKikLt2rXN7kgGlN2pTKlUVspzuru7V8p+iIj+DSsDRFZycnKCVquFr68vXnzxRYSFhWHz5s2m0v4777wDLy8vtGjRAgCQnZ2NZ555BvXq1YO7uzsGDBiAc+fOmfZnMBgQExODevXqoUGDBnjttdfK3cb1n8MERUVFmD59Onx8fODk5IRmzZrhs88+w7lz5xAaGgoAqF+/PmQyGUaPHg2g7PKncXFx8PPzg4uLCwIDA7Fhwwaz59m2bRuaN28OFxcXhIaGmsVJRI6PyQDRA3JxcTHdBS05ORmZmZlISkrCli1bUFJSgvDwcLi5uWH37t34+eef4erqij59+pi2WbBgAeLj47Fq1Srs2bMHV69exaZNm/71OUeNGoUvv/wSS5YswW+//YaVK1eabqn6zTffAAAyMzNx8eJFLF68GAAQFxeHzz//HCtWrMDx48cxZcoUjBgxArt27QJQlrQMHjwY/fv3R0ZGBl544QXMmDGjqg4bEdkjgYjuKzIyUhgwYIAgCIJgNBqFpKQkwcnJSZg6daoQGRkpaDQaoaioyNT/iy++EFq0aCEYjUbTsqKiIsHFxUXYsWOHIAiC4OnpKcybN8+0vqSkRPD29jY9jyAIQvfu3YVXXnlFEARByMzMFAAISUlJ94zxp59+EgAI165dMy27deuWUKdOHWHv3r1mfceNGyc899xzgiAIwsyZM4WAgACz9dOnTy+3LyJyXJwzQGSlLVu2wNXVFSUlJTAajXj++ecxe/ZsREVFoU2bNmbzBH799VecPn0abm5uZvu4desWzpw5A51Oh4sXLyI4ONi0rlatWujYsWO5oYLbMjIyoFAo0L17d6tjPn36NG7cuIEnnnjCbHlxcTHat28PAPjtt9/M4gBgd3dUI6KqxWSAyEqhoaFYvnw5lEolvLy8UKvWnT+funXrmvUtKChAUFAQ1q5dW24/jRo1eqDnd3FxqfA2BQUFAICtW7fioYceMlvHm9UQ0W1MBoisVLduXTRr1syqvh06dMD69evh4eEBlUp1zz6enp745Zdf0K1bNwBAaWkp0tPT0aFDh3v2b9OmDYxGI3bt2oWwsLBy629XJgwGg2lZQEAAnJyccP78eYsVBX9/f2zevNls2b59++7/IonIYXACIVEVGD58OBo2bIgBAwZg9+7dyMrKQkpKCl5++WVcuHABAPDKK6/gvffeQ2JiIk6ePImXXnrpX68R0KRJE0RGRmLs2LFITEw07fOrr74CAPj6+kImk2HLli24dOkSCgoK4ObmhqlTp2LKlClYs2YNzpw5g0OHDmHp0qVYs2YNAGDixIk4deoUpk2bhszMTCQkJCA+Pr6qDxER2REmA0RVoE6dOkhNTUXjxo0xePBg+Pv7Y9y4cbh165apUvDqq69i5MiRiIyMREhICNzc3DBo0KB/3e/y5csxdOhQvPTSS2jZsiXGjx+PwsJCAMBDDz2Et956CzNmzIBGo0F0dDQA4O2338abb76JuLg4+Pv7o0+fPti6dSv8/PwAAI0bN8Y333yDxMREBAYGYsWKFXj33Xer8OgQkb2RCZZmKxEREZEksDJAREQkcUwGiIiIJI7JABERkcQxGSAiIpI4JgNEREQSx2SAiIhI4pgMEBERSRyTASIiIoljMkBERCRxTAaIiIgkjskAERGRxP0/lWqZIESF+JEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# 使用matplotlib绘制混淆矩阵\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(cm, cmap=plt.cm.Oranges)  # 选择颜色映射\n",
    "\n",
    "# 为图添加颜色条\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# 设置坐标轴\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xticklabels([''] + list(np.unique(y_pred)))\n",
    "ax.set_yticklabels([''] + list(np.unique(y_pred)))\n",
    "\n",
    "# 在混淆矩阵的各个单元格中添加数值标签\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, f'{val}', ha='center', va='center', color='black')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy实现LSTM前向推理过程\n",
    "\n",
    "基于numpy实现推理的流程，很容易实现基于C代码实现LSTM的前向推理。\n",
    "\n",
    "### LSTM推理公式\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n",
    "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n",
    "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "    c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n",
    "    h_t = o_t \\odot \\tanh(c_t) \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于numpy实现的LSTM前向推理\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def extract_parameters(model):\n",
    "    parameters = {}\n",
    "    # LSTM层的权重和偏置\n",
    "    parameters['lstm_weights_ih'] = [p.data.numpy() for p in model.lstm.parameters()][0::4]\n",
    "    parameters['lstm_weights_hh'] = [p.data.numpy() for p in model.lstm.parameters()][1::4]\n",
    "    parameters['lstm_biases_ih'] = [p.data.numpy() for p in model.lstm.parameters()][2::4]\n",
    "    parameters['lstm_biases_hh'] = [p.data.numpy() for p in model.lstm.parameters()][3::4]\n",
    "    \n",
    "    # 全连接层的权重和偏置\n",
    "    parameters['fc_weights'] = model.fc.weight.data.numpy()\n",
    "    parameters['fc_biases'] = model.fc.bias.data.numpy()\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def lstm_forward(x, params, hidden_dim, num_layers):\n",
    "    seq_len, input_dim = x.shape\n",
    "    h = np.zeros((num_layers, hidden_dim))\n",
    "    c = np.zeros((num_layers, hidden_dim))\n",
    "    \n",
    "    # for t in range(seq_len):\n",
    "    for layer in range(num_layers):        \n",
    "        print(f'执行第{layer}层')\n",
    "        if layer == 0:\n",
    "            input, hx = x, np.zeros((1, hidden_dim))\n",
    "        else:\n",
    "            input, hx = h[layer-1], np.zeros((1, hidden_dim))\n",
    "        \n",
    "        wi, wf, wg, wo = np.split(params['lstm_weights_ih'][layer], 4)\n",
    "        bi, bf, bg, bo = np.split(params['lstm_biases_ih'][layer], 4)\n",
    "        whi, whf, whg, who = np.split(params['lstm_weights_hh'][layer], 4)\n",
    "        bhi, bhf, bhg, bho = np.split(params['lstm_biases_hh'][layer], 4)\n",
    "        \n",
    "        # print(params['lstm_weights_ih'][layer].shape)\n",
    "        # print(params['lstm_biases_ih'][layer].shape)\n",
    "        # print(params['lstm_weights_hh'][layer].shape)\n",
    "        # print(params['lstm_biases_hh'][layer].shape)\n",
    "        # print(wi.shape, bi.shape, whi.shape, bhi.shape)\n",
    "\n",
    "        # i = sigmoid(np.dot(input, wi.T) + bi + np.dot(hx, whi.T) + bhi)\n",
    "        # f = sigmoid(np.dot(input, wf.T) + bf + np.dot(hx, whf.T) + bhf)\n",
    "        # g = tanh(np.dot(input, wg.T) + bg + np.dot(hx, whg.T) + bhg)\n",
    "        # o = sigmoid(np.dot(input, wo.T) + bo + np.dot(hx, who.T) + bho)\n",
    "        \n",
    "        # 进一步简化\n",
    "        i = sigmoid(np.dot(input, wi.T) + bi + bhi)\n",
    "        f = sigmoid(np.dot(input, wf.T) + bf + bhf)\n",
    "        g = tanh(np.dot(input, wg.T) + bg + bhg)\n",
    "        o = sigmoid(np.dot(input, wo.T) + bo + bho)\n",
    "        \n",
    "        c[layer] = f * c[layer] + i * g\n",
    "        h[layer] = o * tanh(c[layer])\n",
    "    \n",
    "    return h[-1]  # Returning the last hidden state of the last layer\n",
    "\n",
    "def fc_forward(h, params):\n",
    "    return np.dot(params['fc_weights'], h) + params['fc_biases']\n",
    "\n",
    "def model_forward(x, params, num_layers):\n",
    "    h = lstm_forward(x, params, params['fc_weights'].shape[1], num_layers)\n",
    "    output = fc_forward(h, params)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: torch.Size([16, 140])\n",
      "lstm.weight_hh_l0: torch.Size([16, 4])\n",
      "lstm.bias_ih_l0: torch.Size([16])\n",
      "lstm.bias_hh_l0: torch.Size([16])\n",
      "lstm.weight_ih_l1: torch.Size([16, 4])\n",
      "lstm.weight_hh_l1: torch.Size([16, 4])\n",
      "lstm.bias_ih_l1: torch.Size([16])\n",
      "lstm.bias_hh_l1: torch.Size([16])\n",
      "fc.weight: torch.Size([5, 4])\n",
      "fc.bias: torch.Size([5])\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 将模型权重转换为 NumPy 数组\u001b[39;00m\n\u001b[0;32m      9\u001b[0m params \u001b[38;5;241m=\u001b[39m {name: param\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters()}\n\u001b[1;32m---> 11\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mextract_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 读取测试数据集\u001b[39;00m\n\u001b[0;32m     14\u001b[0m data_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../ECG5000/data/ECG5000_TEST.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36mextract_parameters\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# LSTM层的权重和偏置\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_weights_ih\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mparameters()][\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      9\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_weights_hh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mparameters()][\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m     10\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_biases_ih\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mparameters()][\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m4\u001b[39m]\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# LSTM层的权重和偏置\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_weights_ih\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mparameters()][\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      9\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_weights_hh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mparameters()][\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m     10\u001b[0m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_biases_ih\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mparameters()][\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 打印模型的权重\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")\n",
    "print('--------------------------------------------')\n",
    "\n",
    "# 将模型权重转换为 NumPy 数组\n",
    "params = {name: param.detach().cpu().numpy() for name, param in model.named_parameters()}\n",
    "\n",
    "params = extract_parameters(model)\n",
    "\n",
    "# 读取测试数据集\n",
    "data_test = np.loadtxt('../ECG5000/data/ECG5000_TEST.txt')\n",
    "\n",
    "# 获取data和label\n",
    "test_data, test_labels = data_test[:, 1:], data_test[:, 0]-1.0\n",
    "\n",
    "# 随机选择一个测试样本\n",
    "rd_idx = np.random.randint(test_labels.shape[0])\n",
    "rd_idx = 100\n",
    "input_data = test_data[rd_idx,:]\n",
    "\n",
    "# def print_cpp_format(array, array_name=\"arr\"):\n",
    "#     # 将数组元素转换为字符串列表\n",
    "#     elements = map(str, array)\n",
    "#     # 拼接所有元素为一个逗号分隔的字符串\n",
    "#     elements_str = ', '.join(elements)\n",
    "#     # 打印C++风格的数组初始化代码\n",
    "#     print(f\"double {array_name}[] = {{{elements_str}}};\")\n",
    "\n",
    "# print_cpp_format(input_data)\n",
    "\n",
    "input_data = input_data.reshape([1,140])\n",
    "\n",
    "# 执行 LSTM 前向传播\n",
    "output = model_forward(input_data, params, model.lstm.num_layers)\n",
    "\n",
    "# 使用原本model进行推理\n",
    "model.eval()\n",
    "input_data = torch.tensor(input_data.reshape([1,1,140]), dtype=torch.float32).to(device=device)\n",
    "output2 = model(input_data)\n",
    "output2 = output2.detach().cpu().numpy()\n",
    "\n",
    "# 打印两种推理方式的结果，可以看到是一致的\n",
    "print(output, '\\n' , output2)\n",
    "\n",
    "# 预测label\n",
    "predict_ = np.argmax(output)\n",
    "\n",
    "print(f\"预测类型：{predict_}, 真值： {test_labels[rd_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "执行第0层\n",
      "执行第1层\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_lstm_parameters(weights, filename):\n",
    "    # 分割权重和偏置\n",
    "    wi, wf, wg, wo = np.split(weights['lstm.weight_ih_l0'], 4)\n",
    "    bi, bf, bg, bo = np.split(weights['lstm.bias_ih_l0'], 4)\n",
    "    whi, whf, whg, who = np.split(weights['lstm.weight_hh_l0'], 4)\n",
    "    bhi, bhf, bhg, bho = np.split(weights['lstm.bias_hh_l0'], 4)\n",
    "    \n",
    "    # 打开文件进行写入\n",
    "    with open(filename, 'w') as file:\n",
    "        # 写入输入门权重和偏置\n",
    "        file.write(\"Input Gate Weights (wi):\\n\")\n",
    "        file.write(np.array2string(wi) + \"\\n\")\n",
    "        file.write(\"Input Gate Bias (bi):\\n\")\n",
    "        file.write(np.array2string(bi) + \"\\n\")\n",
    "        \n",
    "        # 写入遗忘门权重和偏置\n",
    "        file.write(\"Forget Gate Weights (wf):\\n\")\n",
    "        file.write(np.array2string(wf) + \"\\n\")\n",
    "        file.write(\"Forget Gate Bias (bf):\\n\")\n",
    "        file.write(np.array2string(bf) + \"\\n\")\n",
    "        \n",
    "        # 写入候选门权重和偏置\n",
    "        file.write(\"Candidate Gate Weights (wg):\\n\")\n",
    "        file.write(np.array2string(wg) + \"\\n\")\n",
    "        file.write(\"Candidate Gate Bias (bg):\\n\")\n",
    "        file.write(np.array2string(bg) + \"\\n\")\n",
    "        \n",
    "        # 写入输出门权重和偏置\n",
    "        file.write(\"Output Gate Weights (wo):\\n\")\n",
    "        file.write(np.array2string(wo) + \"\\n\")\n",
    "        file.write(\"Output Gate Bias (bo):\\n\")\n",
    "        file.write(np.array2string(bo) + \"\\n\")\n",
    "        \n",
    "        # 写入隐藏状态权重和偏置\n",
    "        file.write(\"Hidden State Weights (whi, whf, whg, who):\\n\")\n",
    "        file.write(np.array2string(whi) + \"\\n\")\n",
    "        file.write(np.array2string(whf) + \"\\n\")\n",
    "        file.write(np.array2string(whg) + \"\\n\")\n",
    "        file.write(np.array2string(who) + \"\\n\")\n",
    "        \n",
    "        file.write(\"Hidden State Biases (bhi, bhf, bhg, bho):\\n\")\n",
    "        file.write(np.array2string(bhi) + \"\\n\")\n",
    "        file.write(np.array2string(bhf) + \"\\n\")\n",
    "        file.write(np.array2string(bhg) + \"\\n\")\n",
    "        file.write(np.array2string(bho) + \"\\n\")\n",
    "\n",
    "\n",
    "def extract_parameters(model):\n",
    "    parameters = {}\n",
    "    # LSTM层的权重和偏置\n",
    "    parameters['lstm_weights_ih'] = [p.data.numpy() for p in model.lstm.parameters()][0::4]\n",
    "    parameters['lstm_weights_hh'] = [p.data.numpy() for p in model.lstm.parameters()][1::4]\n",
    "    parameters['lstm_biases_ih'] = [p.data.numpy() for p in model.lstm.parameters()][2::4]\n",
    "    parameters['lstm_biases_hh'] = [p.data.numpy() for p in model.lstm.parameters()][3::4]\n",
    "    \n",
    "    # 全连接层的权重和偏置\n",
    "    parameters['fc_weights'] = model.fc.weight.data.numpy()\n",
    "    parameters['fc_biases'] = model.fc.bias.data.numpy()\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def save_lstm_parameters_as_cpp(model, filename):\n",
    "    \n",
    "    # 将模型权重转换为 NumPy 数组\n",
    "    params = extract_parameters(model)\n",
    "    num_layers = model.lstm.num_layers\n",
    "\n",
    "    # 打开文件进行写入\n",
    "    with open(filename, 'w') as file:\n",
    "        def write_array(name, array):\n",
    "            file.write(f\"double {name}[] = {{{', '.join(map(str, array.flatten()))}}};\\n\")\n",
    "        \n",
    "        # 分割权重和偏置\n",
    "        for layer in range(num_layers):        \n",
    "            print(f'执行第{layer}层')\n",
    "            wi, wf, wg, wo = np.split(params['lstm_weights_ih'][layer], 4)\n",
    "            bi, bf, bg, bo = np.split(params['lstm_biases_ih'][layer], 4)\n",
    "            whi, whf, whg, who = np.split(params['lstm_weights_hh'][layer], 4)\n",
    "            bhi, bhf, bhg, bho = np.split(params['lstm_biases_hh'][layer], 4)\n",
    "            \n",
    "            # 写入输入门权重和偏置\n",
    "            write_array(\"wi\" + str(layer), wi)\n",
    "            write_array(\"bi\" + str(layer), bi)\n",
    "            \n",
    "            # 写入遗忘门权重和偏置\n",
    "            write_array(\"wf\" + str(layer), wf)\n",
    "            write_array(\"bf\" + str(layer), bf)\n",
    "            \n",
    "            # 写入候选门权重和偏置\n",
    "            write_array(\"wg\" + str(layer), wg)\n",
    "            write_array(\"bg\" + str(layer), bg)\n",
    "            \n",
    "            # 写入输出门权重和偏置\n",
    "            write_array(\"wo\" + str(layer), wo)\n",
    "            write_array(\"bo\" + str(layer), bo)\n",
    "            \n",
    "            # 写入隐藏状态权重和偏置\n",
    "            write_array(\"whi\" + str(layer), whi)\n",
    "            write_array(\"whf\" + str(layer), whf)\n",
    "            write_array(\"whg\" + str(layer), whg)\n",
    "            write_array(\"who\" + str(layer), who)\n",
    "            \n",
    "            write_array(\"bhi\" + str(layer), bhi)\n",
    "            write_array(\"bhf\" + str(layer), bhf)\n",
    "            write_array(\"bhg\" + str(layer), bhg)\n",
    "            write_array(\"bho\" + str(layer), bho)\n",
    "        \n",
    "        fc_w, fc_b = params['fc_weights'], params['fc_biases']\n",
    "        write_array(\"fc_w\", fc_w) # 注意此处的转置T\n",
    "        write_array(\"fc_b\", fc_b)\n",
    "        \n",
    "\n",
    "# 保存参数文件\n",
    "# save_lstm_parameters(params, 'lstm_parameters.txt')\n",
    "\n",
    "save_lstm_parameters_as_cpp(model, 'lstm_parameters.cpp')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
