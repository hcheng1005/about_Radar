{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 PyTorch 实现一个简单的卷积神经网络 (CNN) 来进行手写数字识别是一个很好的练习。下面是一个完整的示例，包括数据加载、模型定义、训练和评估过程。我们将使用 PyTorch 的内置功能来处理 MNIST 数据集。\n",
    "\n",
    "### 1. 导入必要的库\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "```\n",
    "\n",
    "### 2. 数据预处理和加载\n",
    "\n",
    "```python\n",
    "# 定义转换操作，将数据转换为tensor并进行归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 加载训练数据和测试数据\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "```\n",
    "\n",
    "### 3. 定义CNN模型\n",
    "\n",
    "```python\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "### 4. 训练模型\n",
    "\n",
    "```python\n",
    "# 实例化模型、损失函数和优化器\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# GPU支持\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 训练过程\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "```\n",
    "\n",
    "### 5. 评估模型\n",
    "\n",
    "```python\n",
    "# 测试模型\n",
    "model.eval()  # 设置为评估模式\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "```\n",
    "\n",
    "这个例子展示了如何使用 PyTorch 构建和训练一个简单的 CNN 来识别 MNIST 数据集中的手写数字。你可以根据需要调整模型结构和参数以探索不同配置的性能。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2862723.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 31710914.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1292306.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 18160656.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Epoch [1/5], Loss: 0.0466\n",
      "Epoch [2/5], Loss: 0.0597\n",
      "Epoch [3/5], Loss: 0.0988\n",
      "Epoch [4/5], Loss: 0.0269\n",
      "Epoch [5/5], Loss: 0.0002\n",
      "Accuracy of the model on the 10000 test images: 98.95%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 数据预处理和加载\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 定义CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型、损失函数和优化器\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# GPU支持\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 评估模型\n",
    "model.eval()  # 设置为评估模式\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the 10000 test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型参数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layer.0.weight: 288\n",
      "conv_layer.0.bias: 32\n",
      "conv_layer.3.weight: 18432\n",
      "conv_layer.3.bias: 64\n",
      "fc_layer.0.weight: 401408\n",
      "fc_layer.0.bias: 128\n",
      "fc_layer.2.weight: 1280\n",
      "fc_layer.2.bias: 10\n",
      "Total trainable parameters: 421.642 k\n"
     ]
    }
   ],
   "source": [
    "def count_parameters_detailed(model):\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if parameter.requires_grad:\n",
    "            num_params = parameter.numel()\n",
    "            total_params += num_params\n",
    "            print(f\"{name}: {num_params}\")\n",
    "    print(f'Total trainable parameters: {total_params * 1e-3} k')\n",
    "\n",
    "# 实例化模型\n",
    "model = CNN()\n",
    "\n",
    "# 统计并打印模型的可训练参数总量\n",
    "count_parameters_detailed(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据流\n",
    "\n",
    "在提供的 CNN 模型中，数据流通过几个主要的处理步骤，从输入层到输出层。这里是一个详细的步骤描述，展示了数据如何在模型中流动：\n",
    "\n",
    "### 1. 输入层\n",
    "- **输入数据**：模型接收的输入是 MNIST 数据集的图像，这些图像是灰度图（单通道），每个图像的大小为 28x28 像素。\n",
    "- **数据预处理**：输入数据首先通过一个预处理步骤，包括转换为张量，并标准化。标准化使用均值 0.5 和标准差 0.5 来调整像素值，使其范围在 [-1, 1] 之间。\n",
    "\n",
    "### 2. 第一层卷积层\n",
    "- **卷积操作**：输入图像通过一个包含 32 个过滤器的卷积层，每个过滤器的大小为 3x3，使用 padding=1 来保持图像尺寸。这个步骤帮助提取图像的基本特征。\n",
    "- **ReLU激活函数**：卷积后的特征图通过 ReLU 激活函数，增加非线性，帮助网络学习复杂的模式。\n",
    "- **最大池化**：接着是一个 2x2 的最大池化层，步长为 2。这一步骤减少数据的空间尺寸（从 28x28 到 14x14），减少参数数量和计算量，同时保持重要特征。\n",
    "\n",
    "### 3. 第二层卷积层\n",
    "- **卷积操作**：经过第一层处理后的特征图再次通过一个卷积层，这次是 64 个过滤器，过滤器大小仍为 3x3，使用 padding=1。\n",
    "- **ReLU激活函数**：同样，卷积后的特征图通过 ReLU 激活函数。\n",
    "- **最大池化**：再次应用 2x2 最大池化，步长为 2，将特征图尺寸从 14x14 减少到 7x7。\n",
    "\n",
    "### 4. 全连接层\n",
    "- **展平操作**：经过两次卷积和池化后，特征图需要被展平（flatten），从而可以被全连接层处理。展平后的向量长度为 64（过滤器数量）乘以 7（宽）乘以 7（高）= 3136。\n",
    "- **第一个全连接层**：展平的特征通过一个全连接层，该层有 128 个神经元。\n",
    "- **ReLU激活函数**：全连接层后接一个 ReLU 激活函数。\n",
    "- **第二个全连接层**：最后，数据通过另一个全连接层，这层有 10 个输出神经元，对应于 10 个类别的数字（0到9）。\n",
    "\n",
    "### 5. 输出层\n",
    "- **输出**：最终输出是一个 10 维向量，每个维度代表一个类别的预测概率。通常，这些概率会通过 softmax 函数转换，用于分类任务。\n",
    "\n",
    "这个数据流程描述了如何从输入图像到分类输出的过程，展示了每个步骤如何对数据进行转换和处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been converted to ONNX and saved to ./model.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "\n",
    "# 定义CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型、损失函数和优化器\n",
    "model = CNN()\n",
    "\n",
    "## 模型可视化 （not good）\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "y = model(x)\n",
    "dot = make_dot(y, params=dict(list(model.named_parameters())))\n",
    "dot.render('model_graph', format='png')\n",
    "\n",
    "# 设置导出路径和文件名\n",
    "output_onnx = './model.onnx'\n",
    "\n",
    "# 导出模型\n",
    "torch.onnx.export(model, x, output_onnx, export_params=True, opset_version=10,\n",
    "                  do_constant_folding=True, input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "\n",
    "print(f\"Model has been converted to ONNX and saved to {output_onnx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/20240420094722.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
