# PointPillars: 模型部署与代码详解

- [模型部署](#模型部署)
  - [1.基础模型导出](#1基础模型导出)
    - [a. 模型重写](#a-模型重写)
    - [b. 权重读取](#b-权重读取)
    - [c. 输入定义](#c-输入定义)
    - [d. 导出](#d-导出)
  - [2. 模型简化](#2-模型简化)
    - [a. PPScatterPlugin自定义因子](#a-ppscatterplugin自定义因子)
    - [b. TBD](#b-tbd)
- [工程代码详解](#工程代码详解)
  - [1: 生成PP实例](#1-生成pp实例)
  - [2：模型推理](#2模型推理)
    - [a. 体素化](#a-体素化)
      - [**体素构造：generateVoxels\_random\_kernel**](#体素构造generatevoxels_random_kernel)
      - [**体素4特征生成：generateBaseFeatures\_launch**](#体素4特征生成generatebasefeatures_launch)
      - [**体素10特征生成：generateFeatures\_launch**](#体素10特征生成generatefeatures_launch)
    - [b. backbone推理](#b-backbone推理)
      - [scatter操作](#scatter操作)
    - [c. 后处理](#c-后处理)
      - [1. postprocess\_launch](#1-postprocess_launch)
      - [2. NMS](#2-nms)

---

## 模型部署
[该仓库](https://github.com/NVIDIA-AI-IOT/CUDA-PointPillars)的模型转onnx的过程需要特定的openpcdet版本. 因此修改了一版本的[export脚本](https://github.com/hcheng1005/OpenPCDet/blob/master/tools/onnx_utils_dual_radar/trans_pointpillar.py).

[export.py](./code/trans_pointpillar.py)

### 1.基础模型导出

#### a. 模型重写

模型重写主要是为了清晰模型各个子模块的流程,删除不必要的判断分支.

另外,需要调整部分模型的输入输出.

#### b. 权重读取

```python
"""基于重写的模型定义一个PP"""
model = pointpillars(cfg, np.array([gridx ,gridy, 1]))  
model.to('cuda').eval()

"""加载pth文件"""
checkpoint = torch.load(ckpt, map_location='cuda')

"""获取子模块权重参数"""
dicts = {}
for key in checkpoint["model_state"].keys():
    if "vfe" in key:
        dicts[key] = checkpoint["model_state"][key]
    if "backbone_2d" in key:
        dicts[key] = checkpoint["model_state"][key]
    if "dense_head" in key:
        dicts[key] = checkpoint["model_state"][key]
model.load_state_dict(dicts)
```

#### c. 输入定义

```python
with torch.no_grad():
    MAX_VOXELS = 10000
    dummy_voxels = torch.zeros(
        (MAX_VOXELS, 32, 4),
        dtype=torch.float32,
        device='cuda:0')

    dummy_voxel_idxs = torch.zeros(
        (MAX_VOXELS, 4),
        dtype=torch.int32,
        device='cuda:0')

    dummy_voxel_num = torch.zeros(
        (1),
        dtype=torch.int32,
        device='cuda:0')

    # pytorch don't support dict when export model to onnx.
    # so here is something to change in networek input and output, the dict input --> list input
    # here is three part onnx export from OpenPCDet codebase:
    dummy_input = (dummy_voxels, dummy_voxel_num, dummy_voxel_idxs)
```
#### d. 导出

```python
# 导出pp模型
torch.onnx.export(model,
                dummy_input,
                export_onnx_file,
                export_params=True,        # store the trained parameter weights inside the model file
                opset_version=11,          # the ONNX version to export the model to
                do_constant_folding=True,  # whether to execute constant folding for optimization
                keep_initializers_as_inputs=True,
                input_names = ['voxels', 'voxel_num', 'voxel_idxs'],   # the model's input names
                output_names = ['cls_preds', 'box_preds', 'dir_cls_preds'])# the model's output names
```

### 2. 模型简化
[源文件](https://github.com/hcheng1005/OpenPCDet/blob/master/tools/onnx_utils_dual_radar/simplifier_onnx.py)

[本地文件](./code/simplifier_onnx.py)

####  a. PPScatterPlugin自定义因子

```python
@gs.Graph.register()
def replace_with_clip(self, inputs, outputs):
    for inp in inputs:
        inp.outputs.clear()

    for out in outputs:
        out.inputs.clear()

    op_attrs = dict()
    # op_attrs["dense_shape"] = np.array([496, 640]) #
    op_attrs["dense_shape"] = np.array([248, 320]) # 距离/分辨率

    return self.layer(name="PPScatter_0", op="PPScatterPlugin", inputs=inputs, outputs=outputs, attrs=op_attrs)
```

在[原始工程仓库](https://github.com/NVIDIA-AI-IOT/CUDA-PointPillars)生成trt的脚本如下:

```bash
#!/bin/bash
/usr/src/tensorrt/bin/trtexec --onnx=./model/pointpillar.onnx --fp16 --plugins=build/libpointpillar_core.so --saveEngine=./model/pointpillar.plan --inputIOFormats=fp16:chw,int32:chw,int32:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed > model/pointpillar.8611.log 2>&1
```

GPT解释:

```bash
您提供的命令是一个脚本，使用TensorRT可执行程序trtexec对名为pointpillar.onnx的ONNX模型执行各种操作。以下是命令及其选项的详细说明：

--onnx=./model/pointpillar.onnx：指定ONNX模型文件pointpillar.onnx的路径，该文件位于./model目录中。
--fp16：启用模型在降低精度（FP16）下执行。
--plugins=build/libpointpillar_core.so：指定包含模型所需的自定义TensorRT插件的插件库libpointpillar_core.so的路径。
--saveEngine=./model/pointpillar.plan：在TensorRT优化后，将优化的引擎保存到指定的文件pointpillar.plan中，该文件位于./model目录中。
--inputIOFormats=fp16:chw,int32:chw,int32:chw：指定模型输入数据的格式。输入数据格式设置为FP16和int32的CHW（通道、高度、宽度）格式。
--verbose：在模型执行期间启用详细输出。
--dumpLayerInfo：在模型执行期间转储层信息。
--dumpProfile：在模型执行期间转储性能分析信息。
--separateProfileRun：为每个层运行单独的性能分析。
--profilingVerbosity=detailed：将性能分析信息的详细程度设置为详细。
> model/pointpillar.8611.log 2>&1：将标准输出和标准错误重定向到日志文件pointpillar.8611.log，该文件位于./model目录中。
总体而言，此命令执行TensorRT引擎创建过程，用于pointpillar.onnx模型，具有特定配置，如FP16精度、自定义插件、输入数据格式和详细的性能分析信息。输出和错误消息被重定向到日志文件，以供进一步分析。
```

上述有个关键的地方是就是`plugins=build/libpointpillar_core.so`.

关于该so文件的生成如下:

```bash
sudo apt-get install git-lfs && git lfs install
git clone https://github.com/NVIDIA-AI-IOT/CUDA-PointPillars.git
cd CUDA-PointPillars && . tool/environment.sh
mkdir build && cd build
cmake .. && make -j$(nproc)
cd ../ && sh tool/build_trt_engine.sh
cd build && ./pointpillar ../data/ ../data/ --timer
```

#### b. TBD

## 工程代码详解

### 1: 生成PP实例
```cpp
auto core = create_core();
```

```cpp
// 创建一个指向pointpillar::lidar::Core对象的std::shared_ptr指针的函数
std::shared_ptr<pointpillar::lidar::Core> create_core() {
    // 创建并初始化VoxelizationParameter对象
    // 设置体素化参数，包括最小/最大范围、体素大小、网格大小等
    pointpillar::lidar::VoxelizationParameter vp;
    vp.min_range = nvtype::Float3(0.0, -39.68f, -3.0);
    vp.max_range = nvtype::Float3(69.12f, 39.68f, 1.0);
    vp.voxel_size = nvtype::Float3(0.16f, 0.16f, 4.0f);
    vp.grid_size = vp.compute_grid_size(vp.max_range, vp.min_range, vp.voxel_size);
    vp.max_voxels = 40000;
    vp.max_points_per_voxel = 32;
    vp.max_points = 300000;
    vp.num_feature = 4; // 输入点云原始特征数（x,y,z,idensity）

    // 创建并初始化PostProcessParameter对象
    // 设置后处理参数，包括最小/最大范围和特征尺寸
    pointpillar::lidar::PostProcessParameter pp;
    pp.min_range = vp.min_range;
    pp.max_range = vp.max_range;
    pp.feature_size = nvtype::Int2(vp.grid_size.x / 2, vp.grid_size.y / 2);

    // 创建并初始化CoreParameter对象
    // 将前面设置的VoxelizationParameter和PostProcessParameter赋值给CoreParameter
    pointpillar::lidar::CoreParameter param;
    param.voxelization = vp;
    param.lidar_model = "../model/pointpillar.plan";
    param.lidar_post = pp;

    // 使用CoreParameter创建pointpillar::lidar::Core对象并返回其std::shared_ptr指针
    return pointpillar::lidar::create_core(param);
}
```

### 2：模型推理

```c++
// 模型推理函数
std::vector<BoundingBox> forward_only(const float *lidar_points, int num_points, void *stream) {
    int cappoints = static_cast<int>(capacity_points_);
    if (num_points > cappoints) {
        printf("If it exceeds %d points, the default processing will simply crop it out.\n", cappoints);
    }

    num_points = std::min(cappoints, num_points);

    cudaStream_t _stream = static_cast<cudaStream_t>(stream);
    size_t bytes_points = num_points * param_.voxelization.num_feature * sizeof(float);

    // 输入点云数据拷贝到host（CPU-CPU）
    checkRuntime(cudaMemcpyAsync(lidar_points_host_, lidar_points, bytes_points, cudaMemcpyHostToHost, _stream));

    // host数据拷贝到device（CPU-GPU）
    checkRuntime(cudaMemcpyAsync(lidar_points_device_, lidar_points_host_, bytes_points, cudaMemcpyHostToDevice, _stream));

    // 对输入的点云数据进行体素化处理,生成特征、坐标和参数
    this->lidar_voxelization_->forward(lidar_points_device_, num_points, _stream);

    // 对体素化后的特征进行特征提取和目标检测
    this->lidar_backbone_->forward(this->lidar_voxelization_->features(), this->lidar_voxelization_->coords(), this->lidar_voxelization_->params(), _stream);
    
    // 对检测结果进行后处理,生成最终的边界框信息
    this->lidar_postprocess_->forward(this->lidar_backbone_->cls(), this->lidar_backbone_->box(), this->lidar_backbone_->dir(), _stream);

    return this->lidar_postprocess_->bndBoxVec();
}
```

这段代码是一个名为forward_only的C++函数,它实现了一个前向传播的过程。下面是对该函数的中文解释:

首先,函数检查输入的点云数量num_points是否超过了预设的容量capacity_points_。如果超过了,则会打印一条警告信息,并将点云数量限制在容量内。

然后,函数将输入的点云数据从主机内存(lidar_points)复制到主机临时缓冲区(lidar_points_host_),再从主机缓冲区复制到设备内存(lidar_points_device_),使用异步的cudaMemcpyAsync操作来提高效率。

接下来,函数调用lidar_voxelization_->forward()来对输入的点云数据进行体素化处理,生成特征、坐标和参数。

然后,函数调用lidar_backbone_->forward()来对体素化后的特征进行特征提取和目标检测。

最后,函数调用lidar_postprocess_->forward()来对检测结果进行后处理,生成最终的边界框信息。

函数返回这些边界框信息(bndBoxVec())。

总的来说,这个函数实现了一个完整的点云处理流程,包括`点云预处理`、`体素化`、`特征提取`、`目标检测和边界框生成`等步骤。它是一个典型的基于深度学习的点云处理算法的组成部分
    
#### a. 体素化

点云体素化（pillar化）基于CUDA实现的，总共分为三个步骤：

1. 随机体素生成
   
2. 体素4特征生成
   
3. 体素10特征生成

```c++
// points and voxels must be of half type
virtual void forward(const float *_points, int num_points, void *stream) override
{
cudaStream_t _stream = reinterpret_cast<cudaStream_t>(stream);

checkRuntime(cudaMemsetAsync(params_input_, 0, sizeof(unsigned int), _stream));

// 随机体素生成
checkRuntime(generateVoxels_random_launch(_points, num_points,
                                            param_.min_range.x, param_.max_range.x,
                                            param_.min_range.y, param_.max_range.y,
                                            param_.min_range.z, param_.max_range.z,
                                            param_.voxel_size.x, param_.voxel_size.y, param_.voxel_size.z,
                                            param_.grid_size.y, param_.grid_size.x,
                                            mask_, voxels_, _stream));
// voxel_features_: 4 channel
checkRuntime(generateBaseFeatures_launch(mask_, voxels_,
                                            param_.grid_size.y, param_.grid_size.x,
                                            params_input_,
                                            voxel_features_,
                                            voxel_num_,
                                            voxel_idxs_, _stream));
// voxel_features_: 10 channel
checkRuntime(generateFeatures_launch(voxel_features_,
                                        voxel_num_,
                                        voxel_idxs_,
                                        params_input_, param_.max_voxels,
                                        param_.voxel_size.x, param_.voxel_size.y, param_.voxel_size.z,
                                        param_.min_range.x, param_.min_range.y, param_.min_range.z,
                                        features_input_, _stream));
}
```

这段代码是一个名为forward的虚函数,它实现了点云的体素化和特征提取过程。下面是对该函数的中文解释:

首先,函数获取了传入的CUDA流_stream。

接下来,函数使用cudaMemsetAsync将输入参数缓冲区params_input_清零。

然后,函数调用g`enerateVoxels_random_launch`内核函数,实现了**随机体素化**的过程。这个过程包括:

- 根据输入点云的范围和体素大小,计算出体素网格的大小。

- 将输入点云随机分配到对应的体素中,并记录每个体素中点的数量。

- 将点云坐标和体素索引信息存储到mask_和voxels_缓冲区中。

接下来,函数调用`generateBaseFeatures_launch`内核函数,计算每个**非空体素**的基础特征。这个过程包括:

- 遍历所有体素,提取每个体素中点的坐标信息。

- 计算每个体素的中心点坐标、最大/最小坐标等基础特征。

- 将这些特征信息存储到voxel_features_和voxel_idxs_缓冲区中。

最后,函数调用`generateFeatures_launch`内核函数,**进一步提取每个体素的特征**。这个过程包括:

- 根据体素大小和位置信息,计算每个体素的相对坐标特征。

- 将这些特征信息存储到features_input_缓冲区中。

总的来说,这个forward函数实现了点云的体素化和特征提取过程,为后续的深度学习模型提供输入特征。这是点云处理算法中的关键步骤之一。



下面具体看下各个模块的具体实现过程：

##### **体素构造：generateVoxels_random_kernel**

```c++
    /**
     * @description: 
     * @return {*}
     */
    static __global__ void generateVoxels_random_kernel(const float *points, size_t points_size,
                                                        float min_x_range, float max_x_range,
                                                        float min_y_range, float max_y_range,
                                                        float min_z_range, float max_z_range,
                                                        float pillar_x_size, float pillar_y_size, float pillar_z_size,
                                                        int grid_y_size, int grid_x_size,
                                                        unsigned int *mask, float *voxels)
    {
      int point_idx = blockIdx.x * blockDim.x + threadIdx.x;
      if (point_idx >= points_size)
        return;

      float4 point = ((float4 *)points)[point_idx];

      // 点云范围筛选
      if (point.x < min_x_range || point.x >= max_x_range || point.y < min_y_range || point.y >= max_y_range || point.z < min_z_range || point.z >= max_z_range)
        return;

      int voxel_idx = floorf((point.x - min_x_range) / pillar_x_size);
      int voxel_idy = floorf((point.y - min_y_range) / pillar_y_size);
      unsigned int voxel_index = voxel_idy * grid_x_size + voxel_idx;

      /*
        这行代码使用了CUDA提供的原子操作atomicAdd。它的作用是:

        获取当前体素索引voxel_index对应的掩码数组mask中的值。
        对该值进行原子加操作,加 1。
        将加 1 后的新值赋给变量point_id。
        这样做的目的是为了给当前点分配一个唯一的ID,该ID表示该点是当前体素中的第几个点。

        使用原子操作是为了确保在多个线程并发访问同一个体素时,不会出现数据竞争的问题。atomicAdd能够保证对mask数组的读改写操作是原子性的,即一次性完成,不会被其他线程打断。
      */
      unsigned int point_id = atomicAdd(&(mask[voxel_index]), 1);

      if (point_id >= POINTS_PER_VOXEL)
        return;

      float *address = voxels + (voxel_index * POINTS_PER_VOXEL + point_id) * 4;
      atomicExch(address + 0, point.x);
      atomicExch(address + 1, point.y);
      atomicExch(address + 2, point.z);
      atomicExch(address + 3, point.w);
    }
```

函数接受以下参数:

**points**: 输入点的内存指针

**points_size**: 输入点的数量

min_x_range, max_x_range, min_y_range, max_y_range, min_z_range, max_z_range: x、y、z坐标的最小和最大范围

pillar_x_size, pillar_y_size, pillar_z_size: 每个体素在x、y、z维度上的大小

grid_y_size, grid_x_size: 网格在y和x维度上的大小

**mask**: 一个掩码数组指针,用于跟踪每个体素中的点数

**voxels**: 输出体素数组的指针

该函数并行执行,每个线程处理一个输入点。

对于每个输入点,函数首先检查点是否在指定范围内。如果不在,函数直接返回,不处理该点。

如果点在范围内,函数根据点的x和y坐标以及体素大小,计算该点所属的体素索引。

`函数然后使用原子操作(atomicAdd)来递增对应体素在mask数组中的点计数`。

如果体素的点计数小于最大点数(POINTS_PER_VOXEL),`函数使用原子操作(atomicExch)将点的x、y、z、w坐标存储在voxels数组中`。

---

```c++
// 计算内存地址
float *address = voxels + (voxel_index * POINTS_PER_VOXEL + point_id) * 4;

// 写入该点云特征
atomicExch(address + 0, point.x);
atomicExch(address + 1, point.y);
atomicExch(address + 2, point.z);
atomicExch(address + 3, point.w);
```

首先,这段代码计算了一个地址指针address,它指向voxels数组中当前体素(voxel_index)对应的存储位置。

voxel_index * POINTS_PER_VOXEL计算了当前体素在voxels数组中的起始位置。
`point_id`是当前点在该体素中的序号。
乘以4是因为每个点由4个float值(x, y, z, w)组成。
接下来,代码使用CUDA提供的原子操作atomicExch将当前点的坐标(x, y, z, w)依次写入到计算出的地址address中。

`atomicExch`是一个原子交换操作,它可以确保多个线程并发访问同一个内存地址时不会出现数据竞争问题。
这样可以确保每个点的坐标信息都能被正确地写入到对应的体素中。
总的来说,这段代码的作用是将当前点的坐标信息以原子方式写入到voxels数组的正确位置,以确保数据的正确性和并发安全性。这是生成体素数据的关键步骤。

---

##### **体素4特征生成：generateBaseFeatures_launch**

```c++
// create 4 channels
cudaError_t generateBaseFeatures_launch(unsigned int *mask, float *voxels,
                                        int grid_y_size, int grid_x_size,
                                        unsigned int *pillar_num,
                                        float *voxel_features,
                                        unsigned int *voxel_num,
                                        unsigned int *voxel_idxs,
                                        cudaStream_t stream)
{
    dim3 threads = {32, 32};
    dim3 blocks = {(grid_x_size + threads.x - 1) / threads.x,
                    (grid_y_size + threads.y - 1) / threads.y};

    generateBaseFeatures_kernel<<<blocks, threads, 0, stream>>>(mask, voxels, grid_y_size, grid_x_size,
                                                                pillar_num,
                                                                voxel_features,
                                                                voxel_num,
                                                                voxel_idxs);
    cudaError_t err = cudaGetLastError();
    return err;
}
```

```c++
// create 4 channels
static __global__ void generateBaseFeatures_kernel(unsigned int *mask, float *voxels,
                                                    int grid_y_size, int grid_x_size,
                                                    unsigned int *pillar_num,
                                                    float *voxel_features,
                                                    unsigned int *voxel_num,
                                                    unsigned int *voxel_idxs)
{
    unsigned int voxel_idx = blockIdx.x * blockDim.x + threadIdx.x;
    unsigned int voxel_idy = blockIdx.y * blockDim.y + threadIdx.y;

    if (voxel_idx >= grid_x_size || voxel_idy >= grid_y_size)
        return;

    unsigned int voxel_index = voxel_idy * grid_x_size + voxel_idx;
    unsigned int count = mask[voxel_index];

    // 判断是否为空pillars
    // 这里的注释说明,函数首先要判断当前处理的体素是否为空体素。
    // 如果体素为空,则直接返回,不需要进行后续的特征提取。
    if (!(count > 0))
        return;
    count = count < POINTS_PER_VOXEL ? count : POINTS_PER_VOXEL;

    unsigned int current_pillarId = 0;
    // 使用原子操作为当前体素分配一个唯一的ID
    // 这个ID将用于后续特征的存储
    current_pillarId = atomicAdd(pillar_num, 1); // pillar_num非空pillar个数++

    voxel_num[current_pillarId] = count;

    uint4 idx = {0, 0, voxel_idy, voxel_idx};
    // 将体素的坐标信息存储到voxel_idxs数组中
    ((uint4 *)voxel_idxs)[current_pillarId] = idx;

    // 遍历该pillar的所有点云
    for (int i = 0; i < count; i++)
    {
        int inIndex = voxel_index * POINTS_PER_VOXEL + i; // 这是每个grid中点云的的索引
        int outIndex = current_pillarId * POINTS_PER_VOXEL + i; // 这是pillar的索引位置
        // 将体素中点的坐标信息存储到voxel_features数组中
        ((float4 *)voxel_features)[outIndex] = ((float4 *)voxels)[inIndex];
    }

    // clear buffer for next infer
    // 最后,函数使用原子操作将mask数组中该体素的值清零,为下一次处理做准备
    // 清空的目的：下次循环的时候，这里已经没有count了，就不会重复执行特征提取步骤
    atomicExch(mask + voxel_index, 0);
}
```

这段代码是一个名为generateBaseFeatures_kernel的CUDA内核函数,它实现了点云体素化过程中的基础特征提取。下面是对该函数的中文解释:

1. 函数首先计算当前线程所处理的体素在网格中的坐标voxel_idx和voxel_idy。

2. 如果线程处理的体素坐标超出了网格范围,则直接返回。

3. 函数根据体素坐标计算出体素在mask数组中的索引voxel_index。

4. 接下来,函数检查该体素是否为空体素。如果是空体素,则直接返回。

5. 如果体素不为空,函数将体素中点的数量count限制在预设的最大值POINTS_PER_VOXEL内。

6. 然后,函数使用原子操作atomicAdd为该体素分配一个唯一的IDcurrent_pillarId。这个ID将用于后续的特征存储。

7. 函数将体素中点的数量count存储到voxel_num数组中,并将体素的坐标信息存储到voxel_idxs数组中。

8. 接下来,函数遍历该体素中的所有点,将它们的坐标信息存储到voxel_features数组中。

9. 最后,函数使用原子操作atomicExch将mask数组中该体素的值清零,为下一次处理做准备。

总的来说,**这个内核函数的主要作用是提取每个非空体素的基础特征,包括体素中点的数量、坐标等信息,为后续的特征提取和深度学习模型提供输入**。这是点云处理算法中的关键步骤之一。

经过上述步骤后，每个feature里面存储的依旧是4维特征。


##### **体素10特征生成：generateFeatures_launch**
```c++
cudaError_t generateFeatures_launch(float *voxel_features,
                                    unsigned int *voxel_num,
                                    unsigned int *voxel_idxs,
                                    unsigned int *params, unsigned int max_voxels,
                                    float voxel_x, float voxel_y, float voxel_z,
                                    float range_min_x, float range_min_y, float range_min_z,
                                    nvtype::half *features,
                                    cudaStream_t stream)
{
    dim3 blocks((max_voxels + WARPS_PER_BLOCK - 1) / WARPS_PER_BLOCK);
    dim3 threads(WARPS_PER_BLOCK * WARP_SIZE);

    generateFeatures_kernel<<<blocks, threads, 0, stream>>>(voxel_features,
                                                            voxel_num,
                                                            voxel_idxs,
                                                            params,
                                                            voxel_x, voxel_y, voxel_z,
                                                            range_min_x, range_min_y, range_min_z,
                                                            (half *)features);

    cudaError_t err = cudaGetLastError();
    return err;
}
```
完整的generateFeatures_kernel代码如下：
[generateFeatures_kernel](./code/CUDA-PointPillars/src/pointpillar/lidar-voxelization.cu#L350)

下面进行步骤分解：

函数的主要作用是将输入的 4 通道体素特征数据转换为 10 通道的特征向量。它接受以下输入参数:

1. voxel_features: 4 通道的体素特征数据
   
2. voxel_num: 每个体素中点的数量
   
3. voxel_idxs: 每个体素的坐标索引
   
4. params: 一些额外的参数,如体素的数量
   
5. voxel_x, voxel_y, voxel_z: 体素的尺寸
   
6. range_min_x, range_min_y, range_min_z: 点云的最小坐标范围
   
7. features: 输出的 10 通道特征向量

代码流程进行详细解析:

**1. 线程索引计算:**

```C++
int pillar_idx = blockIdx.x * WARPS_PER_BLOCK + threadIdx.x / WARP_SIZE;
 int point_idx = threadIdx.x % WARP_SIZE;

 int pillar_idx_inBlock = threadIdx.x / WARP_SIZE;
 unsigned int num_pillars = params[0];

 if (pillar_idx >= num_pillars)
     return;
```

这段代码首先计算出当前线程所处理的体素 ID(pillar_idx)和该体素中点的索引(point_idx)。

同时,它还计算出当前线程在块内的索引(pillar_idx_inBlock)。如果当前线程处理的体素 ID 超出了总体素数量,则直接返回。

**2. 共享内存初始化:**

```C++
__shared__ float4 pillarSM[WARPS_PER_BLOCK][WARP_SIZE];
 __shared__ float4 pillarSumSM[WARPS_PER_BLOCK];
 __shared__ uint4 idxsSM[WARPS_PER_BLOCK];
 __shared__ int pointsNumSM[WARPS_PER_BLOCK];
 __shared__ half pillarOutSM[WARPS_PER_BLOCK][WARP_SIZE][FEATURES_SIZE];

 if (threadIdx.x < WARPS_PER_BLOCK)
 {
     pointsNumSM[threadIdx.x] = voxel_num[blockIdx.x * WARPS_PER_BLOCK + threadIdx.x];
     idxsSM[threadIdx.x] = ((uint4 *)voxel_idxs)[blockIdx.x * WARPS_PER_BLOCK + threadIdx.x];
     pillarSumSM[threadIdx.x] = {0, 0, 0, 0};
 }

 pillarSM[pillar_idx_inBlock][point_idx] = ((float4 *)voxel_features)[pillar_idx * WARP_SIZE + point_idx];
 __syncthreads();

```

这段代码初始化了几个共享内存变量:

- pillarSM: 用于存储每个体素中各点的坐标信息
  
- pillarSumSM: 用于存储每个体素中各坐标维度的累加和
  
- idxsSM: 用于存储每个体素的坐标索引
  
- pointsNumSM: 用于存储每个体素中点的数量
  
- pillarOutSM: 用于存储最终的 10 通道特征向量
  
同时,它还将输入的 voxel_features 数据加载到 pillarSM 中。最后,使用 __syncthreads() 确保所有线程完成了这些初始化操作。

**3. 计算体素中点的平均值:**

```C++
 // calculate sm in a pillar
 if (point_idx < pointsNumSM[pillar_idx_inBlock])
 {
     atomicAdd(&(pillarSumSM[pillar_idx_inBlock].x), pillarSM[pillar_idx_inBlock][point_idx].x);
     atomicAdd(&(pillarSumSM[pillar_idx_inBlock].y), pillarSM[pillar_idx_inBlock][point_idx].y);
     atomicAdd(&(pillarSumSM[pillar_idx_inBlock].z), pillarSM[pillar_idx_inBlock][point_idx].z);
 }
 __syncthreads();

 // feature-mean
 float4 mean;
 float validPoints = pointsNumSM[pillar_idx_inBlock];
 mean.x = pillarSumSM[pillar_idx_inBlock].x / validPoints;
 mean.y = pillarSumSM[pillar_idx_inBlock].y / validPoints;
 mean.z = pillarSumSM[pillar_idx_inBlock].z / validPoints;
这段代码首先使用原子操作(atomicAdd)计算出每个体素中各坐标维度的累加和,存储在 pillarSumSM 中。然后,它计算出每个体素中点的平均值,存储在 mean 变量中。

计算点相对于体素中心的偏移量:

 mean.x = pillarSM[pillar_idx_inBlock][point_idx].x - mean.x;
 mean.y = pillarSM[pillar_idx_inBlock][point_idx].y - mean.y;
 mean.z = pillarSM[pillar_idx_inBlock][point_idx].z - mean.z;

 // calculate offset
 float x_offset = voxel_x / 2 + idxsSM[pillar_idx_inBlock].w * voxel_x + range_min_x;
 float y_offset = voxel_y / 2 + idxsSM[pillar_idx_inBlock].z * voxel_y + range_min_y;
 float z_offset = voxel_z / 2 + idxsSM[pillar_idx_inBlock].y * voxel_z + range_min_z;

 // feature-offset
 float4 center;
 center.x = pillarSM[pillar_idx_inBlock][point_idx].x - x_offset;
 center.y = pillarSM[pillar_idx_inBlock][point_idx].y - y_offset;
 center.z = pillarSM[pillar_idx_inBlock][point_idx].z - z_offset;

```

这段代码**首先计算出每个点相对于体素中心的偏移量,存储在 mean 变量中**。

然后,它**计算出每个体素的中心坐标,并将每个点的坐标减去中心坐标,得到相对于体素中心的偏移量,存储在 center 变量中**。

**4. 存储最终的 10 通道特征向量:**

```C++
// store output
 if (point_idx < pointsNumSM[pillar_idx_inBlock])
 {
     pillarOutSM[pillar_idx_inBlock][point_idx][0] = __float2half(pillarSM[pillar_idx_inBlock][point_idx].x);
     pillarOutSM[pillar_idx_inBlock][point_idx][1] = __float2half(pillarSM[pillar_idx_inBlock][point_idx].y);
     pillarOutSM[pillar_idx_inBlock][point_idx][2] = __float2half(pillarSM[pillar_idx_inBlock][point_idx].z);
     pillarOutSM[pillar_idx_inBlock][point_idx][3] = __float2half(pillarSM[pillar_idx_inBlock][point_idx].w);

     pillarOutSM[pillar_idx_inBlock][point_idx][4] = __float2half(mean.x);
     pillarOutSM[pillar_idx_inBlock][point_idx][5] = __float2half(mean.y);
     pillarOutSM[pillar_idx_inBlock][point_idx][6] = __float2half(mean.z);

     pillarOutSM[pillar_idx_inBlock][point_idx][7] = __float2half(center.x);
     pillarOutSM[pillar_idx_inBlock][point_idx][8] = __float2half(center.y);
     pillarOutSM[pillar_idx_inBlock][point_idx][9] = __float2half(center.z);
 }
 else
 {
     // 如果当前点不在体素内,则填充 0
 }

 __syncthreads();

 for (int i = 0; i < FEATURES_SIZE; i++)
 {
     int outputSMId = pillar_idx_inBlock * WARP_SIZE * FEATURES_SIZE + i * WARP_SIZE + point_idx;
     int outputId = pillar_idx * WARP_SIZE * FEATURES_SIZE + i * WARP_SIZE + point_idx;
     features[outputId] = ((half *)pillarOutSM)[outputSMId];
 }
```

这段代码最终将计算出的 10 通道特征向量存储到 `pillarOutSM` 中。如果当前点不在体素内,则填充 0。最后,它将 `pillarOutSM` 中的数据复制到最终的 `features` 输出数组中。

总的来说,这个 CUDA 内核函数的主要作用是将输入的 4 通道体素特征数据转换为 10 通道的特征向量,这些特征向量包含了体素中点的坐标信息、平均值和偏移量等,为后续的深度学习模型提供更丰富的输入特征。这是点云处理算法中的一个关键步骤。

#### b. backbone推理
backbone推理全程调用trt文件。

```
virtual void forward(const nvtype::half* voxels, const unsigned int* voxel_idxs, const unsigned int* params, void* stream = nullptr) override {
    cudaStream_t _stream = reinterpret_cast<cudaStream_t>(stream);
    engine_->forward({voxels, voxel_idxs, params, cls_, box_, dir_}, static_cast<cudaStream_t>(_stream));
}
```

##### scatter操作

TBD。

#### c. 后处理

后处理模块函数接口：

```c++
virtual void forward(const float* cls, const float* box, const float* dir, void* stream) override {
    cudaStream_t _stream = static_cast<cudaStream_t>(stream);

    checkRuntime(cudaMemsetAsync(object_counter_, 0, sizeof(int), _stream));
    checkRuntime(cudaMemsetAsync(h_mask_, 0, h_mask_size_, _stream));

    checkRuntime(postprocess_launch((float *)cls,
                                    (float *)box,
                                    (float *)dir,
                                    anchors_,
                                    anchor_bottom_heights_,
                                    bndbox_,
                                    score_,
                                    object_counter_,
                                    param_.min_range.x,
                                    param_.max_range.x,
                                    param_.min_range.y,
                                    param_.max_range.y,
                                    param_.feature_size.x,
                                    param_.feature_size.y,
                                    param_.num_anchors,
                                    param_.num_classes,
                                    param_.num_box_values,
                                    param_.score_thresh,
                                    param_.dir_offset,
                                    _stream
                                    ));
    checkRuntime(cudaMemcpyAsync(&bndbox_num_, object_counter_, sizeof(int), cudaMemcpyDeviceToHost, _stream));
    checkRuntime(cudaStreamSynchronize(_stream));

    thrust::device_ptr<combined_float> thr_bndbox_((combined_float *)bndbox_);
    thrust::stable_sort_by_key(thrust::cuda::par.on(_stream), score_, score_ + bndbox_num_, thr_bndbox_, thrust::greater<float>());
    checkRuntime(nms_launch(bndbox_num_, bndbox_, param_.nms_thresh, h_mask_, _stream));

    checkRuntime(cudaMemcpyAsync(h_bndbox_, bndbox_, bndbox_num_ * 9 * sizeof(float), cudaMemcpyDeviceToHost, _stream));
    checkRuntime(cudaStreamSynchronize(_stream));

    int col_blocks = DIVUP(bndbox_num_, NMS_THREADS_PER_BLOCK);
    memset(remv_.data(), 0, col_blocks * sizeof(uint64_t));
    bndbox_num_after_nms_ = 0;

    for (unsigned int i_nms = 0; i_nms < bndbox_num_; i_nms++) {
        unsigned int nblock = i_nms / NMS_THREADS_PER_BLOCK;
        unsigned int inblock = i_nms % NMS_THREADS_PER_BLOCK;

        if (!(remv_[nblock] & (1ULL << inblock))) {
            bndbox_after_nms_[bndbox_num_after_nms_] = *(BoundingBox*)(&h_bndbox_[i_nms * 9]);
            bndbox_num_after_nms_++;
            uint64_t* p = h_mask_ + i_nms * col_blocks;
            for (int j_nms = nblock; j_nms < col_blocks; j_nms++) {
                remv_[j_nms] |= p[j_nms];
            }
        }
    }
}
```

这段代码实现了一个完整的物体检测模型的后处理流程,包括边界框预测、分类结果、方向预测的后处理,以及 NMS 算法的执行。它利用了 CUDA 流和 Thrust 库来提高并行计算的效率和代码的可读性。


##### 1. postprocess_launch

```c++
__global__ void postprocess_kernal(const float *cls_input,
                                  float *box_input,
                                  const float *dir_input,
                                  float *anchors,
                                  float *anchor_bottom_heights,
                                  float *bndbox_output,
                                  float *score_output,
                                  int *object_counter,
                                  const float min_x_range,
                                  const float max_x_range,
                                  const float min_y_range,
                                  const float max_y_range,
                                  const int feature_x_size,
                                  const int feature_y_size,
                                  const int num_anchors,
                                  const int num_classes,
                                  const int num_box_values,
                                  const float score_thresh,
                                  const float dir_offset)
{
  // 获取当前线程所在的块索引和线程索引
  int loc_index = blockIdx.x;
  int ith_anchor = threadIdx.x;

  // 如果线程索引超出锚框数量,直接返回
  if (ith_anchor >= num_anchors)
  {
      return;
  }

  // 计算当前位置在特征图中的列和行索引
  int col = loc_index % feature_x_size;
  int row = loc_index / feature_x_size;

  // 计算当前位置在 x 和 y 轴上的偏移
  float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);
  float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);

  // 计算当前位置和锚框在分类结果中的偏移
  int cls_offset = loc_index * num_anchors * num_classes + ith_anchor * num_classes;

  // 获取当前位置和锚框的分类结果
  const float *scores = cls_input + cls_offset;

  // 找到置信度最高的类别
  float max_score = sigmoid(scores[0]);
  int cls_id = 0;
  for (int i = 1; i < num_classes; i++) {
    float cls_score = sigmoid(scores[i]);
    if (cls_score > max_score) {
      max_score = cls_score;
      cls_id = i;
    }
  }

  // 如果置信度大于阈值,则进行后续处理
  if (max_score >= score_thresh)
  {
    // 计算当前位置和锚框在边界框预测和方向预测中的偏移
    int box_offset = loc_index * num_anchors * num_box_values + ith_anchor * num_box_values;
    int dir_cls_offset = loc_index * num_anchors * 2 + ith_anchor * 2;

    // 获取当前锚框的参数
    float *anchor_ptr = anchors + ith_anchor * 4;
    float z_offset = anchor_ptr[2] / 2 + anchor_bottom_heights[ith_anchor / 2];
    float anchor[7] = {x_offset, y_offset, z_offset, anchor_ptr[0], anchor_ptr[1], anchor_ptr[2], anchor_ptr[3]};

    // 根据边界框预测和锚框参数,计算出实际的边界框坐标
    float *box_encodings = box_input + box_offset;
    float xa = anchor[0];
    float ya = anchor[1];
    float za = anchor[2];
    float dxa = anchor[3];
    float dya = anchor[4];
    float dza = anchor[5];
    float ra = anchor[6];
    float diagonal = sqrtf(dxa * dxa + dya * dya);
    box_encodings[0] = box_encodings[0] * diagonal + xa;
    box_encodings[1] = box_encodings[1] * diagonal + ya;
    box_encodings[2] = box_encodings[2] * dza + za;
    box_encodings[3] = expf(box_encodings[3]) * dxa;
    box_encodings[4] = expf(box_encodings[4]) * dya;
    box_encodings[5] = expf(box_encodings[5]) * dza;
    box_encodings[6] = box_encodings[6] + ra;

    // 根据方向预测,计算出最终的偏航角 `yaw`
    float yaw;
    int dir_label = dir_input[dir_cls_offset] > dir_input[dir_cls_offset + 1] ? 0 : 1;
    float period = 2 * M_PI / 2;
    float val = box_input[box_offset + 6] - dir_offset;
    float dir_rot = val - floor(val / (period + 1e-8) + 0.f) * period;
    yaw = dir_rot + dir_offset + period * dir_label;

    // 使用原子操作更新物体计数器,并将计算出的结果保存到输出缓冲区
    int resCount = (int)atomicAdd(object_counter, 1);
    float *data = bndbox_output + resCount * 9;
    data[0] = box_input[box_offset];
    data[1] = box_input[box_offset + 1];
    data[2] = box_input[box_offset + 2];
    data[3] = box_input[box_offset + 3];
    data[4] = box_input[box_offset + 4];
    data[5] = box_input[box_offset + 5];
    data[6] = yaw;
    *(int *)&data[7] = cls_id;
    data[8] = max_score;
    score_output[resCount] = max_score;
  }
}
```

这段代码是一个 CUDA 内核函数,用于执行物体检测模型的后处理算法。让我们逐步解释这个函数的功能:

1. 线程和块的分配:

    - int loc_index = blockIdx.x;: 获取当前线程所在的块索引,作为特征图中的位置索引。
  
    - int ith_anchor = threadIdx.x;: 获取当前线程在块内的索引,作为锚框的索引。
  
    - 如果 ith_anchor 超出了锚框的数量,则直接返回,不执行后续操作。

2. 计算特征图位置对应的坐标偏移:

    - int col = loc_index % feature_x_size;: 计算当前位置在特征图中的列索引。
  
    - int row = loc_index / feature_x_size;: 计算当前位置在特征图中的行索引。
  
    - float x_offset = min_x_range + col * (max_x_range - min_x_range) / (feature_x_size - 1);: 计算当前位置在 x 轴上的偏移。
  
    - float y_offset = min_y_range + row * (max_y_range - min_y_range) / (feature_y_size - 1);: 计算当前位置在 y 轴上的偏移。

3. 计算分类结果:

    - int cls_offset = loc_index * num_anchors * num_classes + ith_anchor * num_classes;: 计算当前位置和锚框在分类结果中的偏移。
  
    - const float *scores = cls_input + cls_offset;: 获取当前位置和锚框的分类结果。
    
    - 遍历所有类别,找到置信度最高的类别,并记录其类别 ID 和置信度分数。

4. 处理边界框预测:

    - int box_offset = loc_index * num_anchors * num_box_values + ith_anchor * num_box_values;: 计算当前位置和锚框在边界框预测中的偏移。
    
    - int dir_cls_offset = loc_index * num_anchors * 2 + ith_anchor * 2;: 计算当前位置和锚框在方向预测中的偏移。
    
    - 根据锚框的参数和边界框预测,计算出实际的边界框坐标。
    
    - 根据方向预测,计算出最终的偏航角 yaw。

5. 保存结果:

    - 使用原子操作 atomicAdd 更新物体计数器 object_counter。
    
    - 将计算出的边界框信息和分类结果保存到输出缓冲区 bndbox_output 和 score_output 中。   
  
##### 2. NMS
```c++
// 将 bndbox_输出转换为 thrust::device_ptr<combined_float>类型,方便后续使用 thrust 算法进行排序
thrust::device_ptr<combined_float> thr_bndbox_((combined_float *)bndbox_);

// 使用 thrust::stable_sort_by_key 算法对边界框输出进行排序
// 按照置信度 score_ 从高到低排序,同时保持边界框 thr_bndbox_ 与置信度的对应关系
thrust::stable_sort_by_key(thrust::cuda::par.on(_stream), score_, score_ + bndbox_num_, thr_bndbox_, thrust::greater<float>());

// 调用自定义的 NMS (Non-Maximum Suppression) 算法核函数,对排序后的边界框进行非极大值抑制
// 输入参数包括边界框数量 bndbox_num_、边界框数据 bndbox_、NMS 阈值 param_.nms_thresh、输出 mask h_mask_、CUDA 流 _stream
checkRuntime(nms_launch(bndbox_num_, bndbox_, param_.nms_thresh, h_mask_, _stream));
```

- 将 bndbox_ 输出转换为 thrust::device_ptr<combined_float> 类型,方便后续使用 Thrust 算法进行排序。

- 使用 thrust::stable_sort_by_key 算法对边界框输出进行排序。按照置信度 score_ 从高到低排序,同时保持边界框 thr_bndbox_ 与置信度的对应关系。

- 调用自定义的 NMS (Non-Maximum Suppression) 算法核函数,对排序后的边界框进行非极大值抑制。输入参数包括边界框数量 bndbox_num_、边界框数据 bndbox_、NMS 阈值 param_.nms_thresh、输出 mask h_mask_、CUDA 流 _stream。

[NMS模块](./code/CUDA-PointPillars/src/pointpillar/lidar-postprocess.cu#L433) | [IOU计算模块](./code/CUDA-PointPillars/src/pointpillar/lidar-postprocess.cu#L265)

